{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this file I will test the correlation between the samples generated from the esm, the Potts decoder and the true MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luca\\anaconda3\\envs\\IF3\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from encoded_protein_dataset import EncodedProteinDataset#, collate_fn, get_embedding\n",
    "from encoded_protein_dataset_new import get_embedding, EncodedProteinDataset_new, collate_fn_new\n",
    "from pseudolikelihood import get_npll, get_npll_new, get_npll2\n",
    "import torch, torchvision\n",
    "from torch.nn.functional import one_hot\n",
    "from potts_decoder import PottsDecoder\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from functools import partial\n",
    "import biotite.structure\n",
    "from biotite.structure.io import pdbx, pdb\n",
    "from biotite.structure.residues import get_residues\n",
    "from biotite.structure import filter_backbone\n",
    "from biotite.structure import get_chains\n",
    "from biotite.sequence import ProteinSequence\n",
    "from typing import Sequence, Tuple, List\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "\n",
    "#import pytorch_warmup as warmup\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "##TURIN HPC\n",
    "#sys.path.insert(1, \"/Data/silva/esm/\")\n",
    "\n",
    "## EUROPA\n",
    "sys.path.insert(1, \"/home/lucasilva/esm/\")\n",
    "\n",
    "##Lucas computer\n",
    "sys.path.insert(1, \"D:/esm/\")\n",
    "import esm\n",
    "#from esm.inverse_folding import util\n",
    "import esm.pretrained as pretrained\n",
    "from ioutils import read_fasta, read_encodings\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter is:36 length data:36\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luca\\OneDrive\\Phd\\Second_year\\research\\Feinauer\\InverseFolding\\encoded_protein_dataset_new.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter is:100 length data:99\r"
     ]
    }
   ],
   "source": [
    "max_msas = 100\n",
    "msa_dir = \"D:/Data/InverseFolding/msas/\"\n",
    "encoding_dir =\"D:/Data/InverseFolding/structure_encodings/\"\n",
    "\n",
    "\n",
    "train_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'train'), encoding_dir, noise=0.02, max_msas=max_msas)          ## Default value of noise used\n",
    "sequence_test_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'test/sequence'), encoding_dir, noise=0.0, max_msas=max_msas)\n",
    "structure_test_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'test/structure'), encoding_dir, noise=0.0, max_msas=max_msas)\n",
    "superfamily_test_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'test/superfamily'), encoding_dir, noise=0.0, max_msas=max_msas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_structure_size = 1   ### To generate models fix batchsize to one for the moment\n",
    "perc_subset_test = 1.0     ## During the training, for every dataset available we select a random 10% of its samples. Now moved to 100% due to noise in evaluation metrics\n",
    "batch_msa_size = 16\n",
    "q = 21                      ##isn't always 21??\n",
    "collate_fn = partial(collate_fn_new, q=q, batch_msa_size=batch_msa_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_structure_size, collate_fn=collate_fn, shuffle=True)#, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_new(decoder, inputs, eta):\n",
    "    \"\"\"eta is the multiplicative term in front of the penalized negative pseudo-log-likelihood\"\"\"\n",
    "    msas, encodings, padding_mask  = [input.to(device) for input in inputs]\n",
    "    B, M, N = msas.shape\n",
    "    #print(f\"encodings' shape{encodings.shape}, padding mask:{padding_mask.shape}\")\n",
    "    param_embeddings, fields = decoder.forward_new(encodings, padding_mask)\n",
    "    msas_embedded = embedding(msas)\n",
    "\n",
    "    # get npll\n",
    "    npll = get_npll2(msas_embedded, param_embeddings, fields, N, q)\n",
    "    padding_mask_inv = (~padding_mask)\n",
    "    # multiply with the padding mask to filter non-existing residues (this is probably not necessary)       \n",
    "    npll = npll * padding_mask_inv.unsqueeze(1)\n",
    "    npll_mean = torch.sum(npll) / (M * torch.sum(padding_mask_inv))\n",
    "    \n",
    "    Q = torch.einsum('bkuia, buhia->bkhia', \n",
    "                param_embeddings.unsqueeze(2), param_embeddings.unsqueeze(1)).sum(axis=-1)\n",
    "    penalty = eta*(torch.sum(torch.sum(Q,axis=-1)**2) - torch.sum(Q**2) + torch.sum(fields**2))/B\n",
    "    loss_penalty = npll_mean + penalty\n",
    "    return loss_penalty, npll_mean.item() \n",
    "\n",
    "def get_loss(decoder, inputs, eta):\n",
    "    \"\"\"eta is the multiplicative term in front of the penalized negative pseudo-log-likelihood\"\"\"\n",
    "    msas, encodings, padding_mask  = [input.to(device) for input in inputs]\n",
    "    B, M, N = msas.shape\n",
    "    #print(f\"encodings' shape{encodings.shape}, padding mask:{padding_mask.shape}\")\n",
    "    couplings, fields = decoder(encodings, padding_mask)\n",
    "\n",
    "    # embed and reshape to (B, M, N*q)\n",
    "    msas_embedded = embedding(msas).view(B, M, -1)\n",
    "\n",
    "    # get npll\n",
    "    npll = get_npll(msas_embedded, couplings, fields, N, q)\n",
    "    padding_mask_inv = (~padding_mask)\n",
    "\n",
    "    # multiply with the padding mask to filter non-existing residues (this is probably not necessary)       \n",
    "    npll = npll * padding_mask_inv.unsqueeze(1)\n",
    "    penalty = eta*(torch.sum(couplings**2) + torch.sum(fields**2))/B\n",
    "\n",
    "    # the padding mask does not contain the msa dimension so we need to multiply by M\n",
    "    npll_mean = torch.sum(npll) / (M * torch.sum(padding_mask_inv))\n",
    "    loss_penalty = npll_mean + penalty\n",
    "    return loss_penalty, npll_mean.item() \n",
    "    #return loss_penalty\n",
    "\n",
    "def get_loss_loader(decoder, loader, eta):\n",
    "\n",
    "    decoder.eval()\n",
    "    losses = 0\n",
    "    iterator = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs in loader:\n",
    "            iterator+=1\n",
    "            _, npll = get_loss_new(decoder, inputs, eta) \n",
    "            losses+=npll\n",
    "    \n",
    "    return losses/iterator\n",
    "\n",
    "def compute_covariance(msa, q):\n",
    "    \"\"\"\n",
    "    Compute covariance matrix of a given MSA having q different amino acids\n",
    "    \"\"\"\n",
    "    M, N = msa.shape\n",
    "\n",
    "    # One hot encode classes and reshape to create data matrix\n",
    "    D = torch.flatten(one_hot(msa, num_classes=q), start_dim=1).to(torch.float32)\n",
    "\n",
    "    # Remove one amino acid\n",
    "    D = D.view(M, N, q)[:, :, :q-1].flatten(1)\n",
    "\n",
    "    # Compute bivariate frequencies\n",
    "    bivariate_freqs = D.T @ D / M\n",
    "    \n",
    "    # Compute product of univariate frequencies\n",
    "    univariate_freqs = torch.diagonal(bivariate_freqs).view(N*(q-1), 1) @ torch.diagonal(bivariate_freqs).view(1, N*(q-1))\n",
    "\n",
    "    return bivariate_freqs - univariate_freqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "device=0\n",
    "bk_dir= 'D:/Data/InverseFolding/Intermediate_Models/'\n",
    "fname_par = 'model_17_01_2023.pt'\n",
    "checkpoint = torch.load(os.path.join(bk_dir, fname_par))\n",
    "\n",
    "## Load parameters of the mode,\n",
    "q=21\n",
    "args = checkpoint['args']\n",
    "n_layers = args['n_layers']\n",
    "param_embed_dim = d_model = args['param_embed_dim']\n",
    "input_encoding_dim = args['input_encoding_dim']\n",
    "n_heads=args['n_heads']\n",
    "n_param_heads=args['n_param_heads']\n",
    "dropout=args['dropout']\n",
    "\n",
    "decoder = PottsDecoder(q, n_layers, d_model, input_encoding_dim, param_embed_dim, n_heads, n_param_heads, dropout=dropout);\n",
    "decoder.to(device);\n",
    "\n",
    "decoder.load_state_dict(checkpoint['model_state_dict']);\n",
    "decoder.eval();   ##to generate data we need just the forward pass of the model!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we actually do the old forward pass as it outputs directly the copuling matrix and the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luca\\OneDrive\\Phd\\Second_year\\research\\Feinauer\\InverseFolding\\encoded_protein_dataset_new.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n"
     ]
    }
   ],
   "source": [
    "inputs = next(iter(train_loader))\n",
    "msas, encodings, padding_mask  = [input.to(device) for input in inputs]\n",
    "\n",
    "## We have to normalize these!!!! Correct\n",
    "couplings, fields = decoder(encodings, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 348])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msas.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to save them in a _txt_ file in the format that the _C++_ library can read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "B,N,_ = encodings.shape\n",
    "with open(\"couplings_fields.txt\", \"w\") as f:\n",
    "    ## write J\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            for aa1 in range(q):\n",
    "                for aa2 in range(q):\n",
    "                    J_el = couplings[0, i*q+aa1, j*q+aa2].detach().to('cpu').item()\n",
    "                    line = \"J \" + str(i) + \" \" + str(j) + \" \"+ str(aa1) + \" \" + str(aa2) + \" \" + str(J_el) +\"\\n\"\n",
    "                    f.write(line)\n",
    "    \n",
    "    ## write h\n",
    "    for i in range(N):\n",
    "        for aa in range(q):\n",
    "            h_el = fields[0, i*q+aa1].detach().to('cpu').item()\n",
    "            line = \"h \" + str(i) + \" \" + str(aa) + \" \" + str(h_el) + \"\\n\"\n",
    "            f.write(line)\n",
    "\n",
    "## Find faster way to do this, it takes roughly 4mins hour"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I will load the sequences generated from _bmDCA_ and generate their covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_dir = \"../Samples_Potts/YAP1_HUMAN\"\n",
    "file='samples_numerical.txt'\n",
    "with open(os.path.join(samples_dir,file), mode='r') as f:\n",
    "    lines=f.readlines()\n",
    "\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet='ACDEFGHIKLMNPQRSTVWY-'\n",
    "default_index = alphabet.index('-')\n",
    "aa_index = defaultdict(lambda: default_index, {alphabet[i]: i for i in range(len(alphabet))})\n",
    "aa_index_inv = dict(map(reversed, aa_index.items()))\n",
    "\n",
    "char_seq = [] ##36 is the lenght of YAP\n",
    "\n",
    "for i in range(1, len(lines)):\n",
    "    line = lines[i][0:-1].split(\" \") ## I take out the end of file\n",
    "    line_char = [aa_index_inv[int(idx)] for idx in line]\n",
    "    char_seq.append(line_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now re-translate\n",
    "for prot_idx in range(len(char_seq)):\n",
    "    for aa in range(len(char_seq[prot_idx])):\n",
    "        char_seq[prot_idx][aa] = aa_index[char_seq[prot_idx][aa]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = np.array(char_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 36)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_t = torch.tensor(msa, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 20, 20,  ..., 20, 20, 20],\n",
       "        [20, 20, 20,  ..., 20, 20, 20],\n",
       "        [20, 20, 20,  ...,  3, 20, 20],\n",
       "        ...,\n",
       "        [20, 20,  2,  ..., 14, 20, 20],\n",
       "        [20, 20, 20,  ...,  9, 20, 20],\n",
       "        [20, 20, 20,  ...,  0, 20, 20]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = compute_covariance(msa_t, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_4d = cov.reshape(36,20,36, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.6971e-03, -4.7600e-06, -1.7170e-05,  ..., -2.8900e-06,\n",
       "           -3.4000e-06, -2.5500e-06],\n",
       "          [-1.3090e-05, -6.1200e-06, -9.1800e-06,  ..., -8.1600e-06,\n",
       "           -7.1400e-06,  9.5580e-05],\n",
       "          [ 8.3510e-05,  1.9082e-04,  1.3081e-04,  ..., -1.1900e-05,\n",
       "           -9.0100e-06, -1.1390e-05],\n",
       "          ...,\n",
       "          [ 1.5975e-04,  8.5040e-05, -2.9920e-05,  ..., -3.4850e-05,\n",
       "           -9.0100e-06, -8.5000e-06],\n",
       "          [-1.2240e-05, -6.2900e-06,  3.3700e-05,  ..., -8.3300e-06,\n",
       "           -7.6500e-06, -6.6300e-06],\n",
       "          [-3.5700e-06, -3.2300e-06, -2.2100e-06,  ..., -3.0600e-06,\n",
       "            9.6940e-05, -4.2500e-06]],\n",
       "\n",
       "         [[-4.7600e-06,  2.7922e-03, -2.8280e-05,  ..., -4.7600e-06,\n",
       "           -5.6000e-06, -4.2000e-06],\n",
       "          [-2.1560e-05,  1.8992e-04,  1.8488e-04,  ...,  1.8656e-04,\n",
       "           -1.1760e-05,  1.9272e-04],\n",
       "          [ 7.2840e-05, -1.5120e-05, -1.1396e-04,  ...,  1.8040e-04,\n",
       "            8.5160e-05, -1.8760e-05],\n",
       "          ...,\n",
       "          [-2.3100e-04,  1.7536e-04, -4.9280e-05,  ...,  4.2600e-05,\n",
       "           -1.4840e-05, -1.4000e-05],\n",
       "          [ 1.7984e-04, -1.0360e-05,  9.0800e-05,  ..., -1.3720e-05,\n",
       "           -1.2600e-05, -1.0920e-05],\n",
       "          [-5.8800e-06,  1.9468e-04, -3.6400e-06,  ...,  9.4960e-05,\n",
       "           -5.0400e-06,  9.3000e-05]],\n",
       "\n",
       "         [[-1.7170e-05, -2.8280e-05,  9.9980e-03,  ..., -1.7170e-05,\n",
       "           -2.0200e-05, -1.5150e-05],\n",
       "          [ 2.2230e-05,  6.3640e-05,  4.5460e-05,  ..., -4.8480e-05,\n",
       "            5.5758e-04, -2.6260e-05],\n",
       "          [ 2.0203e-04,  4.5460e-05,  3.8893e-04,  ...,  1.2930e-04,\n",
       "           -5.3530e-05,  2.3233e-04],\n",
       "          ...,\n",
       "          [-4.3325e-04,  1.1120e-05, -1.7776e-04,  ..., -7.0500e-06,\n",
       "           -5.3530e-05, -5.0500e-05],\n",
       "          [ 2.7280e-05,  1.6263e-04,  6.1000e-06,  ..., -4.9490e-05,\n",
       "           -4.5450e-05, -3.9390e-05],\n",
       "          [ 7.8790e-05, -1.9190e-05,  8.6870e-05,  ...,  8.1820e-05,\n",
       "           -1.8180e-05, -2.5250e-05]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.8900e-06, -4.7600e-06, -1.7170e-05,  ...,  1.6971e-03,\n",
       "           -3.4000e-06, -2.5500e-06],\n",
       "          [-1.3090e-05,  1.9388e-04,  9.0820e-05,  ...,  9.1840e-05,\n",
       "           -7.1400e-06, -4.4200e-06],\n",
       "          [-1.6490e-05,  9.0820e-05,  3.3081e-04,  ...,  8.8100e-05,\n",
       "            9.0990e-05, -1.1390e-05],\n",
       "          ...,\n",
       "          [ 5.9750e-05, -1.4960e-05, -2.9920e-05,  ..., -3.4850e-05,\n",
       "           -9.0100e-06,  9.1500e-05],\n",
       "          [-1.2240e-05, -6.2900e-06, -6.6300e-05,  ...,  9.1670e-05,\n",
       "           -7.6500e-06, -6.6300e-06],\n",
       "          [-3.5700e-06, -3.2300e-06, -2.2100e-06,  ..., -3.0600e-06,\n",
       "           -3.0600e-06, -4.2500e-06]],\n",
       "\n",
       "         [[-3.4000e-06, -5.6000e-06, -2.0200e-05,  ..., -3.4000e-06,\n",
       "            1.9960e-03, -3.0000e-06],\n",
       "          [ 8.4600e-05, -7.2000e-06,  8.9200e-05,  ..., -9.6000e-06,\n",
       "            9.1600e-05, -5.2000e-06],\n",
       "          [-1.9400e-05, -1.0800e-05,  1.8600e-05,  ...,  8.6000e-05,\n",
       "           -1.0600e-05,  8.6600e-05],\n",
       "          ...,\n",
       "          [-6.5000e-05, -1.7600e-05,  6.4800e-05,  ...,  5.9000e-05,\n",
       "           -1.0600e-05, -1.0000e-05],\n",
       "          [-1.4400e-05, -7.4000e-06,  1.2200e-04,  ..., -9.8000e-06,\n",
       "           -9.0000e-06, -7.8000e-06],\n",
       "          [-4.2000e-06,  9.6200e-05,  9.7400e-05,  ..., -3.6000e-06,\n",
       "           -3.6000e-06, -5.0000e-06]],\n",
       "\n",
       "         [[-2.5500e-06, -4.2000e-06, -1.5150e-05,  ..., -2.5500e-06,\n",
       "           -3.0000e-06,  1.4978e-03],\n",
       "          [-1.1550e-05, -5.4000e-06,  9.1900e-05,  ..., -7.2000e-06,\n",
       "           -6.3000e-06, -3.9000e-06],\n",
       "          [ 8.5450e-05, -8.1000e-06, -6.1050e-05,  ..., -1.0500e-05,\n",
       "           -7.9500e-06, -1.0050e-05],\n",
       "          ...,\n",
       "          [-1.2375e-04, -1.3200e-05, -2.6400e-05,  ...,  6.9250e-05,\n",
       "           -7.9500e-06,  9.2500e-05],\n",
       "          [-1.0800e-05, -5.5500e-06,  4.1500e-05,  ..., -7.3500e-06,\n",
       "           -6.7500e-06, -5.8500e-06],\n",
       "          [-3.1500e-06,  9.7150e-05,  9.8050e-05,  ..., -2.7000e-06,\n",
       "           -2.7000e-06, -3.7500e-06]]],\n",
       "\n",
       "\n",
       "        [[[-1.3090e-05, -2.1560e-05,  2.2230e-05,  ..., -1.3090e-05,\n",
       "            8.4600e-05, -1.1550e-05],\n",
       "          [ 7.6407e-03, -2.7720e-05, -4.1580e-05,  ..., -3.6960e-05,\n",
       "           -3.2340e-05, -2.0020e-05],\n",
       "          [-7.4690e-05,  1.5842e-04,  2.8661e-04,  ...,  4.6100e-05,\n",
       "            5.9190e-05,  4.8410e-05],\n",
       "          ...,\n",
       "          [ 6.4750e-05, -6.7760e-05, -3.5520e-05,  ..., -5.7850e-05,\n",
       "            5.9190e-05, -3.8500e-05],\n",
       "          [ 1.4456e-04, -2.8490e-05, -2.0030e-04,  ...,  6.2270e-05,\n",
       "            6.5350e-05, -3.0030e-05],\n",
       "          [ 8.3830e-05, -1.4630e-05, -1.0010e-05,  ...,  8.6140e-05,\n",
       "           -1.3860e-05, -1.9250e-05]],\n",
       "\n",
       "         [[-6.1200e-06,  1.8992e-04,  6.3640e-05,  ...,  1.9388e-04,\n",
       "           -7.2000e-06, -5.4000e-06],\n",
       "          [-2.7720e-05,  3.5870e-03, -1.9440e-05,  ..., -1.7280e-05,\n",
       "           -1.5120e-05, -9.3600e-06],\n",
       "          [ 1.6508e-04, -1.9440e-05,  5.3480e-05,  ..., -2.5200e-05,\n",
       "            1.8092e-04, -2.4120e-05],\n",
       "          ...,\n",
       "          [ 3.0000e-06,  1.6832e-04, -6.3360e-05,  ..., -7.3800e-05,\n",
       "           -1.9080e-05, -1.8000e-05],\n",
       "          [-2.5920e-05,  8.6680e-05, -1.4040e-04,  ..., -1.7640e-05,\n",
       "           -1.6200e-05, -1.4040e-05],\n",
       "          [-7.5600e-06, -6.8400e-06, -4.6800e-06,  ...,  9.3520e-05,\n",
       "            9.3520e-05, -9.0000e-06]],\n",
       "\n",
       "         [[-9.1800e-06,  1.8488e-04,  4.5460e-05,  ...,  9.0820e-05,\n",
       "            8.9200e-05,  9.1900e-05],\n",
       "          [-4.1580e-05, -1.9440e-05,  5.3708e-03,  ..., -2.5920e-05,\n",
       "           -2.2680e-05, -1.4040e-05],\n",
       "          [-5.2380e-05,  7.0840e-05,  1.8022e-04,  ...,  6.2200e-05,\n",
       "           -2.8620e-05,  6.3820e-05],\n",
       "          ...,\n",
       "          [-2.4550e-04, -4.7520e-05, -9.5040e-05,  ...,  1.8930e-04,\n",
       "           -2.8620e-05, -2.7000e-05],\n",
       "          [ 1.6112e-04, -1.9980e-05,  8.9400e-05,  ..., -2.6460e-05,\n",
       "           -2.4300e-05,  7.8940e-05],\n",
       "          [-1.1340e-05, -1.0260e-05, -7.0200e-06,  ...,  9.0280e-05,\n",
       "           -9.7200e-06,  8.6500e-05]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.1600e-06,  1.8656e-04, -4.8480e-05,  ...,  9.1840e-05,\n",
       "           -9.6000e-06, -7.2000e-06],\n",
       "          [-3.6960e-05, -1.7280e-05, -2.5920e-05,  ...,  4.7770e-03,\n",
       "           -2.0160e-05, -1.2480e-05],\n",
       "          [ 5.3440e-05, -2.5920e-05,  2.0464e-04,  ..., -3.3600e-05,\n",
       "            7.4560e-05, -3.2160e-05],\n",
       "          ...,\n",
       "          [ 1.0400e-04, -4.2240e-05,  1.5520e-05,  ..., -9.8400e-05,\n",
       "           -2.5440e-05,  7.6000e-05],\n",
       "          [ 2.6544e-04, -1.7760e-05, -8.7200e-05,  ..., -2.3520e-05,\n",
       "            7.8400e-05, -1.8720e-05],\n",
       "          [ 8.9920e-05,  9.0880e-05, -6.2400e-06,  ..., -8.6400e-06,\n",
       "           -8.6400e-06, -1.2000e-05]],\n",
       "\n",
       "         [[-7.1400e-06, -1.1760e-05,  5.5758e-04,  ..., -7.1400e-06,\n",
       "            9.1600e-05, -6.3000e-06],\n",
       "          [-3.2340e-05, -1.5120e-05, -2.2680e-05,  ..., -2.0160e-05,\n",
       "            4.1824e-03, -1.0920e-05],\n",
       "          [ 5.9260e-05, -2.2680e-05,  1.2906e-04,  ...,  7.0600e-05,\n",
       "           -2.2260e-05,  7.1860e-05],\n",
       "          ...,\n",
       "          [ 2.5350e-04,  1.6304e-04,  1.2608e-04,  ...,  1.1390e-04,\n",
       "            7.7740e-05, -2.1000e-05],\n",
       "          [ 6.9760e-05, -1.5540e-05,  3.3620e-04,  ..., -2.0580e-05,\n",
       "           -1.8900e-05, -1.6380e-05],\n",
       "          [-8.8200e-06, -7.9800e-06, -5.4600e-06,  ...,  9.2440e-05,\n",
       "           -7.5600e-06, -1.0500e-05]],\n",
       "\n",
       "         [[ 9.5580e-05,  1.9272e-04, -2.6260e-05,  ..., -4.4200e-06,\n",
       "           -5.2000e-06, -3.9000e-06],\n",
       "          [-2.0020e-05, -9.3600e-06, -1.4040e-05,  ..., -1.2480e-05,\n",
       "           -1.0920e-05,  2.5932e-03],\n",
       "          [ 7.4780e-05, -1.4040e-05, -1.0582e-04,  ...,  1.8180e-04,\n",
       "            8.6220e-05,  8.2580e-05],\n",
       "          ...,\n",
       "          [-1.1450e-04, -2.2880e-05, -4.5760e-05,  ..., -5.3300e-05,\n",
       "           -1.3780e-05, -1.3000e-05],\n",
       "          [-1.8720e-05, -9.6200e-06, -1.0140e-04,  ..., -1.2740e-05,\n",
       "            8.8300e-05,  8.9860e-05],\n",
       "          [-5.4600e-06,  9.5060e-05, -3.3800e-06,  ..., -4.6800e-06,\n",
       "           -4.6800e-06, -6.5000e-06]]],\n",
       "\n",
       "\n",
       "        [[[ 8.3510e-05,  7.2840e-05,  2.0203e-04,  ..., -1.6490e-05,\n",
       "           -1.9400e-05,  8.5450e-05],\n",
       "          [-7.4690e-05,  1.6508e-04, -5.2380e-05,  ...,  5.3440e-05,\n",
       "            5.9260e-05,  7.4780e-05],\n",
       "          [ 9.6059e-03, -5.2380e-05, -3.9479e-04,  ..., -6.7900e-05,\n",
       "           -5.1410e-05, -6.4990e-05],\n",
       "          ...,\n",
       "          [-3.0025e-04,  1.4640e-05,  2.9280e-05,  ..., -1.9885e-04,\n",
       "            4.8590e-05,  5.1500e-05],\n",
       "          [-6.9840e-05,  6.4110e-05,  3.2170e-04,  ...,  1.5247e-04,\n",
       "            5.6350e-05, -3.7830e-05],\n",
       "          [ 7.9630e-05,  8.1570e-05, -1.2610e-05,  ...,  8.2540e-05,\n",
       "           -1.7460e-05, -2.4250e-05]],\n",
       "\n",
       "         [[ 1.9082e-04, -1.5120e-05,  4.5460e-05,  ...,  9.0820e-05,\n",
       "           -1.0800e-05, -8.1000e-06],\n",
       "          [ 1.5842e-04, -1.9440e-05,  7.0840e-05,  ..., -2.5920e-05,\n",
       "           -2.2680e-05, -1.4040e-05],\n",
       "          [-5.2380e-05,  5.3708e-03, -2.1978e-04,  ..., -3.7800e-05,\n",
       "           -2.8620e-05, -3.6180e-05],\n",
       "          ...,\n",
       "          [ 5.4500e-05,  5.2480e-05,  4.9600e-06,  ...,  2.8930e-04,\n",
       "           -2.8620e-05, -2.7000e-05],\n",
       "          [ 6.1120e-05,  8.0020e-05, -1.0600e-05,  ...,  7.3540e-05,\n",
       "            7.5700e-05, -2.1060e-05],\n",
       "          [ 8.8660e-05, -1.0260e-05, -7.0200e-06,  ..., -9.7200e-06,\n",
       "            9.0280e-05, -1.3500e-05]],\n",
       "\n",
       "         [[ 1.3081e-04, -1.1396e-04,  3.8893e-04,  ...,  3.3081e-04,\n",
       "            1.8600e-05, -6.1050e-05],\n",
       "          [ 2.8661e-04,  5.3480e-05,  1.8022e-04,  ...,  2.0464e-04,\n",
       "            1.2906e-04, -1.0582e-04],\n",
       "          [-3.9479e-04, -2.1978e-04,  3.9044e-02,  ..., -2.8490e-04,\n",
       "           -2.1571e-04, -2.7269e-04],\n",
       "          ...,\n",
       "          [-3.5775e-04,  3.4184e-04, -1.1632e-04,  ...,  1.0657e-03,\n",
       "            8.4290e-05, -3.5000e-06],\n",
       "          [ 4.0696e-04,  2.4941e-04,  2.1270e-04,  ...,  5.7000e-07,\n",
       "           -8.3150e-05, -1.5873e-04],\n",
       "          [ 1.4530e-05,  1.2267e-04, -5.2910e-05,  ..., -7.3260e-05,\n",
       "           -7.3260e-05, -1.7500e-06]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.1900e-05,  1.8040e-04,  1.2930e-04,  ...,  8.8100e-05,\n",
       "            8.6000e-05, -1.0500e-05],\n",
       "          [ 4.6100e-05, -2.5200e-05,  6.2200e-05,  ..., -3.3600e-05,\n",
       "            7.0600e-05,  1.8180e-04],\n",
       "          [-6.7900e-05, -3.7800e-05, -2.8490e-04,  ...,  6.9510e-03,\n",
       "           -3.7100e-05, -4.6900e-05],\n",
       "          ...,\n",
       "          [-1.7750e-04,  3.8400e-05,  7.6800e-05,  ..., -4.3500e-05,\n",
       "           -3.7100e-05,  6.5000e-05],\n",
       "          [ 4.9600e-05, -2.5900e-05,  2.2700e-04,  ..., -3.4300e-05,\n",
       "           -3.1500e-05,  7.2700e-05],\n",
       "          [-1.4700e-05,  8.6700e-05, -9.1000e-06,  ..., -1.2600e-05,\n",
       "           -1.2600e-05, -1.7500e-05]],\n",
       "\n",
       "         [[-9.0100e-06,  8.5160e-05, -5.3530e-05,  ...,  9.0990e-05,\n",
       "           -1.0600e-05, -7.9500e-06],\n",
       "          [ 5.9190e-05,  1.8092e-04, -2.8620e-05,  ...,  7.4560e-05,\n",
       "           -2.2260e-05,  8.6220e-05],\n",
       "          [-5.1410e-05, -2.8620e-05, -2.1571e-04,  ..., -3.7100e-05,\n",
       "            5.2719e-03, -3.5510e-05],\n",
       "          ...,\n",
       "          [-1.3725e-04, -4.6640e-05,  6.7200e-06,  ..., -8.6500e-06,\n",
       "            7.1910e-05, -2.6500e-05],\n",
       "          [ 6.1840e-05, -1.9610e-05, -1.0670e-04,  ...,  7.4030e-05,\n",
       "           -2.3850e-05, -2.0670e-05],\n",
       "          [-1.1130e-05, -1.0070e-05, -6.8900e-06,  ...,  1.9046e-04,\n",
       "           -9.5400e-06, -1.3250e-05]],\n",
       "\n",
       "         [[-1.1390e-05, -1.8760e-05,  2.3233e-04,  ..., -1.1390e-05,\n",
       "            8.6600e-05, -1.0050e-05],\n",
       "          [ 4.8410e-05, -2.4120e-05,  6.3820e-05,  ..., -3.2160e-05,\n",
       "            7.1860e-05,  8.2580e-05],\n",
       "          [-6.4990e-05, -3.6180e-05, -2.7269e-04,  ..., -4.6900e-05,\n",
       "           -3.5510e-05,  6.6551e-03],\n",
       "          ...,\n",
       "          [-5.2750e-05, -5.8960e-05,  1.8208e-04,  ...,  6.2650e-05,\n",
       "           -3.5510e-05, -3.3500e-05],\n",
       "          [-4.8240e-05,  7.5210e-05,  3.3870e-04,  ..., -3.2830e-05,\n",
       "           -3.0150e-05,  7.3870e-05],\n",
       "          [-1.4070e-05, -1.2730e-05, -8.7100e-06,  ...,  8.7940e-05,\n",
       "           -1.2060e-05, -1.6750e-05]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.5975e-04, -2.3100e-04, -4.3325e-04,  ...,  5.9750e-05,\n",
       "           -6.5000e-05, -1.2375e-04],\n",
       "          [ 6.4750e-05,  3.0000e-06, -2.4550e-04,  ...,  1.0400e-04,\n",
       "            2.5350e-04, -1.1450e-04],\n",
       "          [-3.0025e-04,  5.4500e-05, -3.5775e-04,  ..., -1.7750e-04,\n",
       "           -1.3725e-04, -5.2750e-05],\n",
       "          ...,\n",
       "          [ 7.5694e-02, -7.2600e-04, -1.4520e-03,  ..., -1.6913e-03,\n",
       "           -4.3725e-04, -4.1250e-04],\n",
       "          [ 6.0600e-04, -5.2500e-06,  1.4825e-03,  ...,  9.5750e-05,\n",
       "            6.2875e-04, -2.1750e-05],\n",
       "          [-1.7325e-04,  1.4325e-04,  9.2750e-05,  ...,  1.5150e-04,\n",
       "            5.1500e-05, -6.2500e-06]],\n",
       "\n",
       "         [[ 8.5040e-05,  1.7536e-04,  1.1120e-05,  ..., -1.4960e-05,\n",
       "           -1.7600e-05, -1.3200e-05],\n",
       "          [-6.7760e-05,  1.6832e-04, -4.7520e-05,  ..., -4.2240e-05,\n",
       "            1.6304e-04, -2.2880e-05],\n",
       "          [ 1.4640e-05,  5.2480e-05,  3.4184e-04,  ...,  3.8400e-05,\n",
       "           -4.6640e-05, -5.8960e-05],\n",
       "          ...,\n",
       "          [-7.2600e-04,  8.7226e-03, -1.5488e-04,  ..., -1.8040e-04,\n",
       "           -4.6640e-05, -4.4000e-05],\n",
       "          [ 3.6640e-05, -3.2560e-05, -1.4320e-04,  ..., -4.3120e-05,\n",
       "            6.0400e-05, -3.4320e-05],\n",
       "          [-1.8480e-05,  8.3280e-05,  8.8560e-05,  ..., -1.5840e-05,\n",
       "           -1.5840e-05, -2.2000e-05]],\n",
       "\n",
       "         [[-2.9920e-05, -4.9280e-05, -1.7776e-04,  ..., -2.9920e-05,\n",
       "            6.4800e-05, -2.6400e-05],\n",
       "          [-3.5520e-05, -6.3360e-05, -9.5040e-05,  ...,  1.5520e-05,\n",
       "            1.2608e-04, -4.5760e-05],\n",
       "          [ 2.9280e-05,  4.9600e-06, -1.1632e-04,  ...,  7.6800e-05,\n",
       "            6.7200e-06,  1.8208e-04],\n",
       "          ...,\n",
       "          [-1.4520e-03, -1.5488e-04,  1.7290e-02,  ..., -3.6080e-04,\n",
       "           -9.3280e-05, -8.8000e-05],\n",
       "          [ 2.7328e-04,  3.4880e-05,  2.1360e-04,  ...,  1.1376e-04,\n",
       "            2.2080e-04,  3.1360e-05],\n",
       "          [ 1.6304e-04,  1.6656e-04, -2.2880e-05,  ...,  6.8320e-05,\n",
       "           -3.1680e-05,  5.6000e-05]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4850e-05,  4.2600e-05, -7.0500e-06,  ..., -3.4850e-05,\n",
       "            5.9000e-05,  6.9250e-05],\n",
       "          [-5.7850e-05, -7.3800e-05,  1.8930e-04,  ..., -9.8400e-05,\n",
       "            1.1390e-04, -5.3300e-05],\n",
       "          [-1.9885e-04,  2.8930e-04,  1.0657e-03,  ..., -4.3500e-05,\n",
       "           -8.6500e-06,  6.2650e-05],\n",
       "          ...,\n",
       "          [-1.6913e-03, -1.8040e-04, -3.6080e-04,  ...,  2.0080e-02,\n",
       "           -1.0865e-04, -1.0250e-04],\n",
       "          [ 2.5240e-04,  1.2415e-04,  4.0050e-04,  ..., -1.0045e-04,\n",
       "           -9.2250e-05,  1.2005e-04],\n",
       "          [ 1.5695e-04, -3.8950e-05,  2.7335e-04,  ...,  2.6310e-04,\n",
       "           -3.6900e-05,  4.8750e-05]],\n",
       "\n",
       "         [[-9.0100e-06, -1.4840e-05, -5.3530e-05,  ..., -9.0100e-06,\n",
       "           -1.0600e-05, -7.9500e-06],\n",
       "          [ 5.9190e-05, -1.9080e-05, -2.8620e-05,  ..., -2.5440e-05,\n",
       "            7.7740e-05, -1.3780e-05],\n",
       "          [ 4.8590e-05, -2.8620e-05,  8.4290e-05,  ..., -3.7100e-05,\n",
       "            7.1910e-05, -3.5510e-05],\n",
       "          ...,\n",
       "          [-4.3725e-04, -4.6640e-05, -9.3280e-05,  ..., -1.0865e-04,\n",
       "            5.2719e-03, -2.6500e-05],\n",
       "          [-3.8160e-05, -1.9610e-05, -1.0670e-04,  ..., -2.5970e-05,\n",
       "            7.6150e-05,  7.9330e-05],\n",
       "          [-1.1130e-05, -1.0070e-05, -6.8900e-06,  ..., -9.5400e-06,\n",
       "            1.9046e-04,  8.6750e-05]],\n",
       "\n",
       "         [[-8.5000e-06, -1.4000e-05, -5.0500e-05,  ...,  9.1500e-05,\n",
       "           -1.0000e-05,  9.2500e-05],\n",
       "          [-3.8500e-05, -1.8000e-05, -2.7000e-05,  ...,  7.6000e-05,\n",
       "           -2.1000e-05, -1.3000e-05],\n",
       "          [ 5.1500e-05, -2.7000e-05, -3.5000e-06,  ...,  6.5000e-05,\n",
       "           -2.6500e-05, -3.3500e-05],\n",
       "          ...,\n",
       "          [-4.1250e-04, -4.4000e-05, -8.8000e-05,  ..., -1.0250e-04,\n",
       "           -2.6500e-05,  4.9750e-03],\n",
       "          [ 2.6400e-04, -1.8500e-05,  1.0500e-04,  ..., -2.4500e-05,\n",
       "           -2.2500e-05, -1.9500e-05],\n",
       "          [ 8.9500e-05, -9.5000e-06, -6.5000e-06,  ..., -9.0000e-06,\n",
       "           -9.0000e-06, -1.2500e-05]]],\n",
       "\n",
       "\n",
       "        [[[-1.2240e-05,  1.7984e-04,  2.7280e-05,  ..., -1.2240e-05,\n",
       "           -1.4400e-05, -1.0800e-05],\n",
       "          [ 1.4456e-04, -2.5920e-05,  1.6112e-04,  ...,  2.6544e-04,\n",
       "            6.9760e-05, -1.8720e-05],\n",
       "          [-6.9840e-05,  6.1120e-05,  4.0696e-04,  ...,  4.9600e-05,\n",
       "            6.1840e-05, -4.8240e-05],\n",
       "          ...,\n",
       "          [ 6.0600e-04,  3.6640e-05,  2.7328e-04,  ...,  2.5240e-04,\n",
       "           -3.8160e-05,  2.6400e-04],\n",
       "          [ 7.1482e-03, -2.6640e-05, -2.8080e-04,  ..., -3.5280e-05,\n",
       "           -3.2400e-05, -2.8080e-05],\n",
       "          [-1.5120e-05, -1.3680e-05, -9.3600e-06,  ...,  1.8704e-04,\n",
       "           -1.2960e-05, -1.8000e-05]],\n",
       "\n",
       "         [[-6.2900e-06, -1.0360e-05,  1.6263e-04,  ..., -6.2900e-06,\n",
       "           -7.4000e-06, -5.5500e-06],\n",
       "          [-2.8490e-05,  8.6680e-05, -1.9980e-05,  ..., -1.7760e-05,\n",
       "           -1.5540e-05, -9.6200e-06],\n",
       "          [ 6.4110e-05,  8.0020e-05,  2.4941e-04,  ..., -2.5900e-05,\n",
       "           -1.9610e-05,  7.5210e-05],\n",
       "          ...,\n",
       "          [-5.2500e-06, -3.2560e-05,  3.4880e-05,  ...,  1.2415e-04,\n",
       "           -1.9610e-05, -1.8500e-05],\n",
       "          [-2.6640e-05,  3.6863e-03, -1.4430e-04,  ..., -1.8130e-05,\n",
       "           -1.6650e-05, -1.4430e-05],\n",
       "          [ 9.2230e-05, -7.0300e-06, -4.8100e-06,  ..., -6.6600e-06,\n",
       "            9.3340e-05, -9.2500e-06]],\n",
       "\n",
       "         [[ 3.3700e-05,  9.0800e-05,  6.1000e-06,  ..., -6.6300e-05,\n",
       "            1.2200e-04,  4.1500e-05],\n",
       "          [-2.0030e-04, -1.4040e-04,  8.9400e-05,  ..., -8.7200e-05,\n",
       "            3.3620e-04, -1.0140e-04],\n",
       "          [ 3.2170e-04, -1.0600e-05,  2.1270e-04,  ...,  2.2700e-04,\n",
       "           -1.0670e-04,  3.3870e-04],\n",
       "          ...,\n",
       "          [ 1.4825e-03, -1.4320e-04,  2.1360e-04,  ...,  4.0050e-04,\n",
       "           -1.0670e-04,  1.0500e-04],\n",
       "          [-2.8080e-04, -1.4430e-04,  3.7479e-02,  ..., -1.9110e-04,\n",
       "           -1.7550e-04, -1.5210e-04],\n",
       "          [ 1.8100e-05,  1.2590e-04,  2.4930e-04,  ...,  2.2980e-04,\n",
       "            3.2980e-04,  1.0250e-04]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.3300e-06, -1.3720e-05, -4.9490e-05,  ...,  9.1670e-05,\n",
       "           -9.8000e-06, -7.3500e-06],\n",
       "          [ 6.2270e-05, -1.7640e-05, -2.6460e-05,  ..., -2.3520e-05,\n",
       "           -2.0580e-05, -1.2740e-05],\n",
       "          [ 1.5247e-04,  7.3540e-05,  5.7000e-07,  ..., -3.4300e-05,\n",
       "            7.4030e-05, -3.2830e-05],\n",
       "          ...,\n",
       "          [ 9.5750e-05, -4.3120e-05,  1.1376e-04,  ..., -1.0045e-04,\n",
       "           -2.5970e-05, -2.4500e-05],\n",
       "          [-3.5280e-05, -1.8130e-05, -1.9110e-04,  ...,  4.8760e-03,\n",
       "           -2.2050e-05, -1.9110e-05],\n",
       "          [-1.0290e-05,  9.0690e-05, -6.3700e-06,  ..., -8.8200e-06,\n",
       "           -8.8200e-06,  8.7750e-05]],\n",
       "\n",
       "         [[-7.6500e-06, -1.2600e-05, -4.5450e-05,  ..., -7.6500e-06,\n",
       "           -9.0000e-06, -6.7500e-06],\n",
       "          [ 6.5350e-05, -1.6200e-05, -2.4300e-05,  ...,  7.8400e-05,\n",
       "           -1.8900e-05,  8.8300e-05],\n",
       "          [ 5.6350e-05,  7.5700e-05, -8.3150e-05,  ..., -3.1500e-05,\n",
       "           -2.3850e-05, -3.0150e-05],\n",
       "          ...,\n",
       "          [ 6.2875e-04,  6.0400e-05,  2.2080e-04,  ..., -9.2250e-05,\n",
       "            7.6150e-05, -2.2500e-05],\n",
       "          [-3.2400e-05, -1.6650e-05, -1.7550e-04,  ..., -2.2050e-05,\n",
       "            4.4797e-03, -1.7550e-05],\n",
       "          [-9.4500e-06,  9.1450e-05, -5.8500e-06,  ..., -8.1000e-06,\n",
       "           -8.1000e-06,  1.8875e-04]],\n",
       "\n",
       "         [[-6.6300e-06, -1.0920e-05, -3.9390e-05,  ..., -6.6300e-06,\n",
       "           -7.8000e-06, -5.8500e-06],\n",
       "          [-3.0030e-05, -1.4040e-05,  7.8940e-05,  ..., -1.8720e-05,\n",
       "           -1.6380e-05,  8.9860e-05],\n",
       "          [-3.7830e-05, -2.1060e-05, -1.5873e-04,  ...,  7.2700e-05,\n",
       "           -2.0670e-05,  7.3870e-05],\n",
       "          ...,\n",
       "          [-2.1750e-05, -3.4320e-05,  3.1360e-05,  ...,  1.2005e-04,\n",
       "            7.9330e-05, -1.9500e-05],\n",
       "          [-2.8080e-05, -1.4430e-05, -1.5210e-04,  ..., -1.9110e-05,\n",
       "           -1.7550e-05,  3.8848e-03],\n",
       "          [-8.1900e-06, -7.4100e-06, -5.0700e-06,  ..., -7.0200e-06,\n",
       "            9.2980e-05, -9.7500e-06]]],\n",
       "\n",
       "\n",
       "        [[[-3.5700e-06, -5.8800e-06,  7.8790e-05,  ..., -3.5700e-06,\n",
       "           -4.2000e-06, -3.1500e-06],\n",
       "          [ 8.3830e-05, -7.5600e-06, -1.1340e-05,  ...,  8.9920e-05,\n",
       "           -8.8200e-06, -5.4600e-06],\n",
       "          [ 7.9630e-05,  8.8660e-05,  1.4530e-05,  ..., -1.4700e-05,\n",
       "           -1.1130e-05, -1.4070e-05],\n",
       "          ...,\n",
       "          [-1.7325e-04, -1.8480e-05,  1.6304e-04,  ...,  1.5695e-04,\n",
       "           -1.1130e-05,  8.9500e-05],\n",
       "          [-1.5120e-05,  9.2230e-05,  1.8100e-05,  ..., -1.0290e-05,\n",
       "           -9.4500e-06, -8.1900e-06],\n",
       "          [ 2.0956e-03, -3.9900e-06, -2.7300e-06,  ..., -3.7800e-06,\n",
       "           -3.7800e-06, -5.2500e-06]],\n",
       "\n",
       "         [[-3.2300e-06,  1.9468e-04, -1.9190e-05,  ..., -3.2300e-06,\n",
       "            9.6200e-05,  9.7150e-05],\n",
       "          [-1.4630e-05, -6.8400e-06, -1.0260e-05,  ...,  9.0880e-05,\n",
       "           -7.9800e-06,  9.5060e-05],\n",
       "          [ 8.1570e-05, -1.0260e-05,  1.2267e-04,  ...,  8.6700e-05,\n",
       "           -1.0070e-05, -1.2730e-05],\n",
       "          ...,\n",
       "          [ 1.4325e-04,  8.3280e-05,  1.6656e-04,  ..., -3.8950e-05,\n",
       "           -1.0070e-05, -9.5000e-06],\n",
       "          [-1.3680e-05, -7.0300e-06,  1.2590e-04,  ...,  9.0690e-05,\n",
       "            9.1450e-05, -7.4100e-06],\n",
       "          [-3.9900e-06,  1.8964e-03, -2.4700e-06,  ..., -3.4200e-06,\n",
       "           -3.4200e-06, -4.7500e-06]],\n",
       "\n",
       "         [[-2.2100e-06, -3.6400e-06,  8.6870e-05,  ..., -2.2100e-06,\n",
       "            9.7400e-05,  9.8050e-05],\n",
       "          [-1.0010e-05, -4.6800e-06, -7.0200e-06,  ..., -6.2400e-06,\n",
       "           -5.4600e-06, -3.3800e-06],\n",
       "          [-1.2610e-05, -7.0200e-06, -5.2910e-05,  ..., -9.1000e-06,\n",
       "           -6.8900e-06, -8.7100e-06],\n",
       "          ...,\n",
       "          [ 9.2750e-05,  8.8560e-05, -2.2880e-05,  ...,  2.7335e-04,\n",
       "           -6.8900e-06, -6.5000e-06],\n",
       "          [-9.3600e-06, -4.8100e-06,  2.4930e-04,  ..., -6.3700e-06,\n",
       "           -5.8500e-06, -5.0700e-06],\n",
       "          [-2.7300e-06, -2.4700e-06,  1.2983e-03,  ..., -2.3400e-06,\n",
       "           -2.3400e-06, -3.2500e-06]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.0600e-06,  9.4960e-05,  8.1820e-05,  ..., -3.0600e-06,\n",
       "           -3.6000e-06, -2.7000e-06],\n",
       "          [ 8.6140e-05,  9.3520e-05,  9.0280e-05,  ..., -8.6400e-06,\n",
       "            9.2440e-05, -4.6800e-06],\n",
       "          [ 8.2540e-05, -9.7200e-06, -7.3260e-05,  ..., -1.2600e-05,\n",
       "            1.9046e-04,  8.7940e-05],\n",
       "          ...,\n",
       "          [ 1.5150e-04, -1.5840e-05,  6.8320e-05,  ...,  2.6310e-04,\n",
       "           -9.5400e-06, -9.0000e-06],\n",
       "          [ 1.8704e-04, -6.6600e-06,  2.2980e-04,  ..., -8.8200e-06,\n",
       "           -8.1000e-06, -7.0200e-06],\n",
       "          [-3.7800e-06, -3.4200e-06, -2.3400e-06,  ...,  1.7968e-03,\n",
       "           -3.2400e-06, -4.5000e-06]],\n",
       "\n",
       "         [[ 9.6940e-05, -5.0400e-06, -1.8180e-05,  ..., -3.0600e-06,\n",
       "           -3.6000e-06, -2.7000e-06],\n",
       "          [-1.3860e-05,  9.3520e-05, -9.7200e-06,  ..., -8.6400e-06,\n",
       "           -7.5600e-06, -4.6800e-06],\n",
       "          [-1.7460e-05,  9.0280e-05, -7.3260e-05,  ..., -1.2600e-05,\n",
       "           -9.5400e-06, -1.2060e-05],\n",
       "          ...,\n",
       "          [ 5.1500e-05, -1.5840e-05, -3.1680e-05,  ..., -3.6900e-05,\n",
       "            1.9046e-04, -9.0000e-06],\n",
       "          [-1.2960e-05,  9.3340e-05,  3.2980e-04,  ..., -8.8200e-06,\n",
       "           -8.1000e-06,  9.2980e-05],\n",
       "          [-3.7800e-06, -3.4200e-06, -2.3400e-06,  ..., -3.2400e-06,\n",
       "            1.7968e-03, -4.5000e-06]],\n",
       "\n",
       "         [[-4.2500e-06,  9.3000e-05, -2.5250e-05,  ..., -4.2500e-06,\n",
       "           -5.0000e-06, -3.7500e-06],\n",
       "          [-1.9250e-05, -9.0000e-06,  8.6500e-05,  ..., -1.2000e-05,\n",
       "           -1.0500e-05, -6.5000e-06],\n",
       "          [-2.4250e-05, -1.3500e-05, -1.7500e-06,  ..., -1.7500e-05,\n",
       "           -1.3250e-05, -1.6750e-05],\n",
       "          ...,\n",
       "          [-6.2500e-06, -2.2000e-05,  5.6000e-05,  ...,  4.8750e-05,\n",
       "            8.6750e-05, -1.2500e-05],\n",
       "          [-1.8000e-05, -9.2500e-06,  1.0250e-04,  ...,  8.7750e-05,\n",
       "            1.8875e-04, -9.7500e-06],\n",
       "          [-5.2500e-06, -4.7500e-06, -3.2500e-06,  ..., -4.5000e-06,\n",
       "           -4.5000e-06,  2.4937e-03]]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_4d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let us load the MSA of YAP and see if we are able to recover the covariance of the MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_YAP_path = \"D:\\Data\\InverseFolding\\Mutational_Data\\msa_full_YAP\"\n",
    "with open(msa_YAP_path, mode=\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "lines = lines[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>UniRef50_UPI000D50330B WW domain with PPxY motif n=1 Tax=Homo sapiens TaxID=9606 RepID=UPI000D50330B'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1][0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa = []\n",
    "for line in range(len(lines)):\n",
    "    if line%2 == 0:\n",
    "        seq_str = 'DVP'+lines[line][0:-1]+'RKA'\n",
    "        seq_num = []\n",
    "        for char in seq_str:\n",
    "            seq_num.append(aa_index[char])\n",
    "        msa.append(seq_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9456, 36])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_true = torch.tensor(msa)\n",
    "msa_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us see if the other file has similar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"D:/Data/InverseFolding/Mutational_Data/alphafold_results_wildtype/YAP1_HUMAN_1_b0.5.a2m.a3m\"\n",
    "with open(fpath, mode=\"r\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_new = []\n",
    "for line in range(len(lines)):\n",
    "    if line%2 == 0:\n",
    "        ## Take the end of sequence file\n",
    "        seq_str = lines[line][0:-1]\n",
    "        seq_num = []\n",
    "        for char in seq_str:\n",
    "            seq_num.append(aa_index[char])\n",
    "        if len(seq_num) == 36:\n",
    "            msa_new.append(seq_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_new = torch.tensor(msa_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        [ 2,  7, 12,  ..., 14, 14,  0],\n",
       "        [11, 16, 12,  ..., 14,  8, 15],\n",
       "        ...,\n",
       "        [20, 20, 20,  ..., 14, 20, 20],\n",
       "        [ 2,  8,  3,  ..., 14, 20, 20],\n",
       "        [20, 20, 20,  ..., 14, 20, 20]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        ...,\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        ...,\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0],\n",
       "        [ 2, 17, 12,  ..., 14,  8,  0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_true = compute_covariance(msa_true[::,::], q=21)\n",
    "cov_true_new = compute_covariance(msa_new[::,::], q=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7970)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = torch.sum(cov_true * cov_true_new)/torch.sqrt(torch.sum(cov_true**2)*torch.sum(cov_true_new**2))\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_true = compute_covariance(msa_true, q=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = torch.sum(cov_true * cov)/torch.sqrt(torch.sum(cov_true**2)*torch.sum(cov**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5333)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5323)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_new = torch.sum(cov_true_new * cov)/torch.sqrt(torch.sum(cov_true_new**2)*torch.sum(cov**2))\n",
    "corr_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/Luca/OneDrive/Phd/Second_year/research/Feinauer/Samples_esm/output/sampled_seqs.fasta\", mode=\"r\") as f:\n",
    "    lines=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_esm = []\n",
    "for line in range(len(lines)):\n",
    "    if line%2 != 0:\n",
    "        seq_str = lines[line][0:-1]\n",
    "        seq_num = []\n",
    "        for char in seq_str:\n",
    "            seq_num.append(aa_index[char])\n",
    "        msa_esm.append(seq_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 36])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_esm = torch.tensor(msa_esm)\n",
    "msa_esm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GMEPPEGWEKRKTKEGDEVWFHKGTNTWTYTDPRTQ\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_esm = compute_covariance(msa_esm, q=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4115)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_new = torch.sum(cov_true_new * cov_esm)/torch.sqrt(torch.sum(cov_true_new**2)*torch.sum(cov_esm**2))\n",
    "corr_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 720])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_esm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 720])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IF3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef468693205e50fc967ab488061515ab821b0c81a84b9cd6a21a9f585a4dae20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
