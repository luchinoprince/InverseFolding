{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this file I will create the independent probabilities for the different MSAs in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "\n",
    "sys.path.insert(1, \"./../util\")\n",
    "sys.path.insert(1, \"./../model\")\n",
    "from pseudolikelihood import get_npll2, get_npll_indep\n",
    "from encoded_protein_dataset_new import get_embedding#, dynamic_collate_fn\n",
    "import torch, torchvision\n",
    "from biotite.structure.io import pdbx, pdb\n",
    "\n",
    "\n",
    "from ioutils import read_fasta, read_encodings\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at iteration:9 out of 2750\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_825905/83664716.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  msa = torch.tensor(msa, dtype=torch.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at iteration:1375 out of 2750\r"
     ]
    }
   ],
   "source": [
    "q=21\n",
    "embedding = get_embedding(q)\n",
    "train_dir = \"/home/luchinoprince/split2/test/structure/\"\n",
    "#train_dir = \"/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/msas/train\"\n",
    "nfiles = len(os.listdir(train_dir))\n",
    "iterator=0\n",
    "for fname in os.listdir(train_dir):\n",
    "    if (fname.endswith(\"pt\") and (not fname.startswith(\"pi_\"))):\n",
    "        iterator+=1\n",
    "        print(f\"We are at iteration:{iterator} out of {nfiles}\", end=\"\\r\")\n",
    "        fpath = os.path.join(train_dir, fname)\n",
    "        msa = torch.load(fpath)\n",
    "        msa = torch.tensor(msa, dtype=torch.int)\n",
    "        msa_embedded = embedding(msa)\n",
    "        M = msa_embedded.shape[0]\n",
    "        ni = msa_embedded.sum(axis=0)\n",
    "        pi = ni/M\n",
    "        fsave = 'pi_' + fname\n",
    "        torch.save(pi, os.path.join(train_dir, fsave))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = get_embedding(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_embedded = embedding(msa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9894, 119, 21])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msa_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = msa_embedded.shape[0]\n",
    "ni = msa_embedded.sum(axis=0)\n",
    "pi = ni/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 2.5713e-01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         7.4287e-01],\n",
       "        [2.4257e-03, 2.0214e-04, 0.0000e+00,  ..., 5.2557e-03, 2.5975e-02,\n",
       "         5.6691e-01],\n",
       "        [4.5987e-02, 4.0429e-04, 4.6493e-02,  ..., 1.1118e-03, 1.8193e-03,\n",
       "         5.3628e-01],\n",
       "        ...,\n",
       "        [8.9954e-03, 2.0214e-04, 9.9353e-02,  ..., 1.0107e-04, 0.0000e+00,\n",
       "         3.8397e-01],\n",
       "        [4.1844e-02, 5.2557e-03, 8.0857e-03,  ..., 1.3746e-02, 7.0750e-03,\n",
       "         5.6691e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         6.2027e-01]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=\"pi_ciao.a3m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
