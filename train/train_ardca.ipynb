{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook I will try to train the model  which gives rise to the arDCA. We can keep the loss the same, as the pseudo likelihood for this model coincides with the true likelihood(I think)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "\n",
    "sys.path.insert(1, \"./../util\")\n",
    "sys.path.insert(1, \"./../model\")\n",
    "from encoded_protein_dataset_new import get_embedding, EncodedProteinDataset_new, collate_fn_new#, dynamic_collate_fn\n",
    "from pseudolikelihood import get_npll2, get_npll, get_npll3\n",
    "import torch, torchvision\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from potts_decoder import PottsDecoder\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from functools import partial\n",
    "import biotite.structure\n",
    "from biotite.structure.io import pdbx, pdb\n",
    "from biotite.structure.residues import get_residues\n",
    "from biotite.structure import filter_backbone\n",
    "from biotite.structure import get_chains\n",
    "from biotite.sequence import ProteinSequence\n",
    "from typing import Sequence, Tuple, List\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#import pytorch_warmup as warmup\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n",
    "\n",
    "##TURIN HPC\n",
    "#sys.path.insert(1, \"/Data/silva/esm/\")\n",
    "\n",
    "## EUROPA\n",
    "#sys.path.insert(1, \"/home/lucasilva/esm/\")\n",
    "\n",
    "##Lucas computer\n",
    "sys.path.insert(1, \"/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/esm/\")\n",
    "import esm\n",
    "#from esm.inverse_folding import util\n",
    "import esm.pretrained as pretrained\n",
    "from ioutils import read_fasta, read_encodings\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "from Bio import SeqIO\n",
    "\n",
    "from dynamic_loader import dynamic_collate_fn, dynamic_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter is:288 length data:287\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/Inverse_Folding/train/./../util/encoded_protein_dataset_new.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxh02.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1vwxh02_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/3o58E00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/3o58E00_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/2wc7A01.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/2wc7A01_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxP00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1vwxP00_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxG01.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1vwxG01_train.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxg01_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/3nskB00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/3nskB00_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1dosA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1dosA00_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1ivnA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1ivnA00_train.a3m.pt\n",
      "No encoding file found for MSA file:  3o58e00_train.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxp00_train.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxH02_train.a3m.pt\n",
      "No encoding file found for MSA file:  3o58e00_test.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxg01_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxP00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/1vwxP00_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1dosA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/1dosA00_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/3nskB00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/3nskB00_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/2wc7A01.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/2wc7A01_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxh02.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/1vwxh02_test.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxH02_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxG01.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/1vwxG01_test.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxp00_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/3o58E00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/3o58E00_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1ivnA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/1ivnA00_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/4xhyA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/structure/4xhyA00.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1nthA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/superfamily/1nthA00.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1mdcA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/superfamily/1mdcA00.a3m.pt\n",
      "Counter is:2679 length data:2671\r"
     ]
    }
   ],
   "source": [
    "### IDEA: MSAS PROCEDURE CAN GIVE DIFFERENT OUTPUT SHAPES? ASK\n",
    "max_msas = None\n",
    "#msa_dir = \"/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/msas/\"\n",
    "msa_dir = \"/home/luchinoprince/split2/\"\n",
    "#encoding_dir =\"/media/luchinoce/split2/\"\n",
    "encoding_dir =\"/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/\"\n",
    "\n",
    "train_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'train'), encoding_dir, noise=0.02, max_msas=max_msas)          ## Default value of noise used\n",
    "sequence_test_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'test/sequence'), encoding_dir, noise=0.0, max_msas=max_msas)\n",
    "structure_test_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'test/structure'), encoding_dir, noise=0.0, max_msas=max_msas)\n",
    "superfamily_test_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'test/superfamily'), encoding_dir, noise=0.0, max_msas=max_msas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_structure_size_train = 1### I think with empty GPU we can go up to 16 easily\n",
    "batch_structure_size=16\n",
    "perc_subset_test = 1.0     ## During the training, for every dataset available we select a random 10% of its samples\n",
    "batch_msa_size = 128 ### old is 32, original is 16\n",
    "q = 21 ##isn't always 21\n",
    "#dynamic_collate_fn\n",
    "\n",
    "collate_fn = partial(dynamic_collate_fn, q=q, batch_size=batch_structure_size, batch_msa_size=batch_msa_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_structure_size_train, collate_fn=collate_fn, shuffle=True,\n",
    "num_workers=1, pin_memory=True)\n",
    "\n",
    "\n",
    "sequence_test_loader = DataLoader(sequence_test_dataset, batch_size=batch_structure_size, collate_fn=collate_fn, shuffle=False, \n",
    "num_workers=4, pin_memory=True, sampler=RandomSampler(sequence_test_dataset, replacement=True, num_samples=int(0.1*len(sequence_test_dataset))))\n",
    "\n",
    "structure_test_loader = DataLoader(structure_test_dataset, batch_size=batch_structure_size, collate_fn=collate_fn, shuffle=False, \n",
    "num_workers=4, pin_memory=True, sampler=RandomSampler(structure_test_dataset, replacement=True, num_samples=int(perc_subset_test*len(structure_test_dataset))))\n",
    "\n",
    "superfamily_test_loader = DataLoader(superfamily_test_dataset, batch_size=batch_structure_size, collate_fn=collate_fn, shuffle=False, \n",
    "num_workers=4, pin_memory=True, sampler=RandomSampler(superfamily_test_dataset, replacement=True, num_samples=int(perc_subset_test*len(superfamily_test_dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(22, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = None\n",
    "embedding = None\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed = 24877\n",
    "torch.random.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "update_steps = 2100000 #525000                                      ##Usual values are update steps=10^5, test_steps=10^2\n",
    "test_steps = 70000 #17500\n",
    "bk_iter = False                                                  ## This tells us how ofter we save a model(default values is every ten-thousand updates)\n",
    "#n_epochs = update_steps//(len(train_dataset)//batch_structure_size)   ## the other update steps will be used for \"partial epochs\", I want to save the last complet epoch\n",
    "#print(f\"With update_steps:{update_steps} we will do {n_epochs} full epochs\")\n",
    "\n",
    "input_encoding_dim = 512\n",
    "param_embed_dim = 512\n",
    "n_param_heads = 48\n",
    "d_model = 512 ##old 512\n",
    "n_heads = 8 ## old 8\n",
    "n_layers = 6\n",
    "## Check before running which is the GPU which is free the most and put it as the running device\n",
    "device = 0        ## DON'T SET TO ONE OTHER THAN IN SPECIAL SPECIAL OCCASIONS, VERY NOISYYYYY!\n",
    "dropout = 0.1\n",
    "\n",
    "decoder = PottsDecoder(q, n_layers, d_model, input_encoding_dim, param_embed_dim, n_heads, n_param_heads, dropout=dropout)\n",
    "decoder.to(device)\n",
    "embedding = get_embedding(q)\n",
    "embedding.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HERE I USE THE OLD INEFFICIENT FORM FOR THE LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(decoder, inputs, eta_J, eta_h):\n",
    "    \"\"\"eta is the multiplicative term in front of the penalized negative pseudo-log-likelihood\"\"\"\n",
    "    msas, encodings, padding_mask  = [input.to(device) for input in inputs]\n",
    "    B, M, N = msas.shape\n",
    "    #print(f\"encodings' shape{encodings.shape}, padding mask:{padding_mask.shape}\")\n",
    "    couplings, fields = decoder.forward_ardca(encodings, padding_mask)\n",
    "    # embed and reshape to (B, M, N*q)\n",
    "    msas_embedded = embedding(msas).view(B, M, -1)\n",
    "\n",
    "    # get npll\n",
    "    npll = get_npll3(msas_embedded, couplings, fields, N, q)\n",
    "    padding_mask_inv = (~padding_mask)\n",
    "\n",
    "    # multiply with the padding mask to filter non-existing residues (this is probably not necessary)       \n",
    "    #npll = npll * padding_mask_inv.unsqueeze(1)\n",
    "    npll = npll.reshape((B,M,-1)) * padding_mask_inv.unsqueeze(1)\n",
    "    penalty = eta_J*(torch.sum(couplings**2))/B + eta_h*(torch.sum(fields**2))/B\n",
    "\n",
    "    # the padding mask does not contain the msa dimension so we need to multiply by M\n",
    "    npll_mean = torch.sum(npll) / (M * torch.sum(padding_mask_inv))\n",
    "    loss_penalty = npll_mean + penalty\n",
    "    return loss_penalty, npll_mean.item() \n",
    "\n",
    "\n",
    "def get_loss_loader(decoder, loader, eta_J, eta_h):\n",
    "    decoder.eval()\n",
    "    losses = []\n",
    "    #with torch.no_grad():\n",
    "    for effective_batch_size, inputs_packed in loader:\n",
    "        npll_full = 0\n",
    "        for inputs in inputs_packed:\n",
    "            mini_batch_size = inputs[0].shape[0]\n",
    "            #_, npll = get_loss_indep(decoder, inputs, eta_J, eta_h) ## For independent model without couplings\n",
    "            _, npll = get_loss(decoder, inputs, eta_J, eta_h)\n",
    "            npll_full += npll*mini_batch_size/effective_batch_size\n",
    "        losses.append(npll_full)\n",
    "            #del inputs\n",
    "    \n",
    "    return np.mean(losses)\n",
    "\n",
    "def train(decoder, inputs_packed, eta_J, eta_h, optimizer, scaler):\n",
    "    effective_batch_size = inputs_packed[0]\n",
    "    loss_penalty_full = 0\n",
    "    train_loss_full = 0\n",
    "    optimizer.zero_grad(set_to_none=True)                           ## set previous gradients to 0\n",
    "    with torch.cuda.amp.autocast():  ## autocasting mixed precision\n",
    "        for inputs in inputs_packed[1]:\n",
    "            mini_batch_size = inputs[0].shape[0]\n",
    "            #loss_penalty, train_batch_loss = get_loss_indep(decoder, inputs, eta_J, eta_h)    ## get the current loss for the batch this is for the independent training\n",
    "            loss_penalty, train_batch_loss = get_loss(decoder, inputs, eta_J, eta_h)\n",
    "            loss_penalty = loss_penalty * mini_batch_size/effective_batch_size\n",
    "            train_batch_loss = train_batch_loss * mini_batch_size/effective_batch_size\n",
    "            #loss_penalty.backward()                         ## Get gradients\n",
    "            scaler.scale(loss_penalty).backward()\n",
    "            loss_penalty_full += loss_penalty.detach()\n",
    "            train_loss_full += train_batch_loss\n",
    "    \n",
    "    \n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    #optimizer.step()   \n",
    "\n",
    "    return loss_penalty_full, train_loss_full\n",
    "\n",
    "def train_stable(decoder, inputs_packed, eta_J, eta_h, optimizer, scaler):\n",
    "    \"\"\"This training does not use an autoscaler/mixed precision.\"\"\"\n",
    "    effective_batch_size = inputs_packed[0]\n",
    "    loss_penalty_full = 0\n",
    "    train_loss_full = 0\n",
    "    optimizer.zero_grad(set_to_none=True)                           ## set previous gradients to 0\n",
    "    #with torch.cuda.amp.autocast():  ## autocasting mixed precision\n",
    "    for inputs in inputs_packed[1]:\n",
    "        mini_batch_size = inputs[0].shape[0]\n",
    "        #loss_penalty, train_batch_loss = get_loss_indep(decoder, inputs, eta_J, eta_h)    ## get the current loss for the batch this is for the independent training\n",
    "        loss_penalty, train_batch_loss = get_loss(decoder, inputs, eta_J, eta_h)\n",
    "        loss_penalty = loss_penalty * mini_batch_size/effective_batch_size\n",
    "        train_batch_loss = train_batch_loss * mini_batch_size/effective_batch_size\n",
    "        loss_penalty.backward()                         ## Get gradients\n",
    "        #scaler.scale(loss_penalty).backward()\n",
    "        loss_penalty_full += loss_penalty.detach()\n",
    "        train_loss_full += train_batch_loss\n",
    "    \n",
    "    \n",
    "    #scaler.step(optimizer)\n",
    "    #scaler.update()\n",
    "    optimizer.step()   \n",
    "\n",
    "    return loss_penalty_full, train_loss_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_step: 577731, epoch: 25.72  train: 2.14, sequence: 2.76, structure: 2.74, superfamily: 2.74:  28%|██▊       | 577731/2100000 [6:11:11<16:18:03, 25.94it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m inputs_packed \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     32\u001b[0m     decoder\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 34\u001b[0m     loss_penalty, train_batch_loss \u001b[39m=\u001b[39m train(decoder, inputs_packed, eta_J, eta_h, optimizer, scaler)\n\u001b[1;32m     35\u001b[0m     loss_penalty\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m     36\u001b[0m     \u001b[39m#optimizer.step()                                ## Do a step of GD\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 50\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(decoder, inputs_packed, eta_J, eta_h, optimizer, scaler)\u001b[0m\n\u001b[1;32m     48\u001b[0m mini_batch_size \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     49\u001b[0m \u001b[39m#loss_penalty, train_batch_loss = get_loss_indep(decoder, inputs, eta_J, eta_h)    ## get the current loss for the batch this is for the independent training\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m loss_penalty, train_batch_loss \u001b[39m=\u001b[39m get_loss(decoder, inputs, eta_J, eta_h)\n\u001b[1;32m     51\u001b[0m loss_penalty \u001b[39m=\u001b[39m loss_penalty \u001b[39m*\u001b[39m mini_batch_size\u001b[39m/\u001b[39meffective_batch_size\n\u001b[1;32m     52\u001b[0m train_batch_loss \u001b[39m=\u001b[39m train_batch_loss \u001b[39m*\u001b[39m mini_batch_size\u001b[39m/\u001b[39meffective_batch_size\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mget_loss\u001b[0;34m(decoder, inputs, eta_J, eta_h)\u001b[0m\n\u001b[1;32m      4\u001b[0m B, M, N \u001b[39m=\u001b[39m msas\u001b[39m.\u001b[39mshape\n\u001b[1;32m      5\u001b[0m \u001b[39m#print(f\"encodings' shape{encodings.shape}, padding mask:{padding_mask.shape}\")\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m couplings, fields \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mforward_ardca(encodings, padding_mask)\n\u001b[1;32m      7\u001b[0m \u001b[39m# embed and reshape to (B, M, N*q)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m msas_embedded \u001b[39m=\u001b[39m embedding(msas)\u001b[39m.\u001b[39mview(B, M, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/Inverse_Folding/train/./../model/potts_decoder.py:280\u001b[0m, in \u001b[0;36mPottsDecoder.forward_ardca\u001b[0;34m(self, encodings, padding_mask)\u001b[0m\n\u001b[1;32m    278\u001b[0m param_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_linear(param_embeddings)\n\u001b[1;32m    279\u001b[0m \u001b[39m#with profiler.record_function(\"Get params\"):\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m couplings, fields \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_params_ardca(param_embeddings, N, padding_mask)\n\u001b[1;32m    282\u001b[0m \u001b[39mreturn\u001b[39;00m couplings, fields\n",
      "File \u001b[0;32m~/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/Inverse_Folding/train/./../model/potts_decoder.py:247\u001b[0m, in \u001b[0;36mPottsDecoder._get_params_ardca\u001b[0;34m(self, param_embeddings, N, padding_mask)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39m# create mask for couplings\u001b[39;00m\n\u001b[1;32m    246\u001b[0m t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq)\n\u001b[0;32m--> 247\u001b[0m mask_couplings \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m torch\u001b[39m.\u001b[39;49mblock_diag(\u001b[39m*\u001b[39;49m([t] \u001b[39m*\u001b[39;49m N)))\u001b[39m.\u001b[39;49mto(couplings\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    248\u001b[0m mask_couplings\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    250\u001b[0m couplings \u001b[39m=\u001b[39m couplings \u001b[39m*\u001b[39m mask_couplings\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#summary_writer = SummaryWriter(log_dir='runs/indep_model')#log_dir=logdir)\n",
    "summary_writer = SummaryWriter()\n",
    "layout = {\n",
    "    \"metrics\": {\n",
    "        \"loss\": [\"Multiline\", [\"loss/train\", \"loss/sequence\", \"loss/structure\", \"loss/superfamily\"]],}\n",
    "}\n",
    "summary_writer.add_custom_scalars(layout)\n",
    "\n",
    "## Let us also save the hyperparameters\n",
    "#with summary_writer as w:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "lr = 2.5*1e-4#3.5e-4\n",
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr)\n",
    "eta_J = 0.0#1e-4#2.15e-6\n",
    "eta_h = 0.0#1e-4#6.51e-4\n",
    "\n",
    "\n",
    "hyperparams = {'lr':lr, 'eta_J':eta_J, 'eta_h':eta_h, 'batch_size':batch_structure_size, 'batch_msa_size':batch_msa_size, 'n_param_heads':n_param_heads, 'n_layers':n_layers, \n",
    "                'dropout':dropout, 'param_embed_dim':param_embed_dim, 'n_heads': n_heads}\n",
    "\n",
    "start = time.time()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "with tqdm(total = update_steps) as pbar: ##This is used to have the nice loading bar while training\n",
    "    train_loss = 0\n",
    "    update_step = 0\n",
    "    max_gpu=0\n",
    "    train_batch_losses = []\n",
    "    epoch = 0.0\n",
    "    while update_step < update_steps:\n",
    "        for inputs_packed in train_loader:\n",
    "            decoder.train()\n",
    "\n",
    "            loss_penalty, train_batch_loss = train(decoder, inputs_packed, eta_J, eta_h, optimizer, scaler)\n",
    "            loss_penalty.detach()\n",
    "            #optimizer.step()                                ## Do a step of GD\n",
    "            update_step += 1                                ## Increase update step (the update steps will count also different batches within the same epoch)\n",
    "            epoch = update_step / len(train_loader)\n",
    "            \n",
    "            train_batch_losses.append(train_batch_loss) ## Here we append the lossess in the different batches within the same epoch\n",
    "            \n",
    "            ## We want to keep track of the test loss not at every batch, too costrly otherwise. Usually set to once every 100.\n",
    "            if (update_step  == 1) or (epoch % 5 == 0):\n",
    "                #check_aux = train_batch_losses.copy()\n",
    "                #print(check_aux)\n",
    "                train_loss = np.mean(train_batch_losses)\n",
    "                with torch.no_grad():\n",
    "                    #print(\"beginning first test\")\n",
    "                    sequence_test_loss = get_loss_loader(decoder, sequence_test_loader, eta_J, eta_h)\n",
    "                    #print(\"Completed first test\")\n",
    "                    structure_test_loss = get_loss_loader(decoder, structure_test_loader, eta_J, eta_h)\n",
    "                    #print(\"Completed second test\")\n",
    "                    superfamily_test_loss = get_loss_loader(decoder, superfamily_test_loader, eta_J, eta_h)\n",
    "                    #print(\"Completed third test\")\n",
    "\n",
    "                summary_writer.add_scalar('loss/train', train_loss, update_step)\n",
    "                summary_writer.add_scalar('loss/sequence', sequence_test_loss, update_step)\n",
    "                summary_writer.add_scalar('loss/structure', structure_test_loss, update_step)\n",
    "                summary_writer.add_scalar('loss/superfamily', superfamily_test_loss, update_step)\n",
    "\n",
    "                ## UNCOMMENT THIS!\n",
    "                train_batch_losses = []\n",
    "\n",
    "        \n",
    "            pbar.set_description(f'update_step: {update_step}, epoch: {epoch:.2f}  train: {train_loss:.2f}, sequence: {sequence_test_loss:.2f}, structure: {structure_test_loss:.2f}, superfamily: {superfamily_test_loss:.2f}')\n",
    "            pbar.update(1)\n",
    "            \n",
    "print(f\"It took {time.time()-start} seconds\")\n",
    "save_metrics = {'loss/train': train_loss, 'loss/sequence': sequence_test_loss, \n",
    "'loss/structure': structure_test_loss, 'loss/superfamily': superfamily_test_loss}\n",
    "summary_writer.add_hparams(hyperparams, save_metrics)\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "check=0\n",
    "for inputs_packed in train_loader:\n",
    "    for inputs in inputs_packed[1]:\n",
    "        check+=1\n",
    "        #decoder.train()\n",
    "        #loss_penalty, train_batch_loss = train(decoder, inputs_packed, eta_J, eta_h, optimizer, scaler)\n",
    "        msas, encodings, padding_mask  = [input.to(device) for input in inputs]\n",
    "        B, M, N = msas.shape\n",
    "        #print(f\"encodings' shape{encodings.shape}, padding mask:{padding_mask.shape}\")\n",
    "        couplings, fields = decoder.forward_ardca(encodings, padding_mask)\n",
    "        if check>1:\n",
    "            break\n",
    "    if check>1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (couplings == 0).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb268258af0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0084, -0.0434,  0.0264,  ..., -0.2201, -0.1952,  3.4901],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_dir= '/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/Intermediate_Models'\n",
    "fname_par = 'model_11_07_2023_epoch_' + str(94.0)+'_ardca' + '.pt'\n",
    "\n",
    "                ##Arguments of the model, could be inferred\n",
    "args_run = {}\n",
    "args_run['n_layers'] = n_layers\n",
    "args_run['input_encoding_dim'] = input_encoding_dim\n",
    "args_run['param_embed_dim'] = param_embed_dim\n",
    "args_run['n_heads'] = n_heads\n",
    "args_run['n_param_heads'] = n_param_heads\n",
    "args_run['dropout'] = dropout\n",
    "\n",
    "\n",
    "\n",
    "d = {}\n",
    "d['epoch'] = epoch\n",
    "d['update_step'] = update_step\n",
    "d['batch_size'] = batch_structure_size_train\n",
    "d['seed'] = seed\n",
    "d['eta_h'] = eta_h\n",
    "d['eta_J'] = eta_J\n",
    "d['noise'] = 0.02\n",
    "d['args_run'] = args_run\n",
    "d['model_state_dict'] = decoder.state_dict()\n",
    "d['optimizer_state_dict'] = optimizer.state_dict()\n",
    "\n",
    "torch.save(d, os.path.join(bk_dir, fname_par))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
