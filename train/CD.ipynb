{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook I will implement the training with the Contrastive-Divergence loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "\n",
    "sys.path.insert(1, \"/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/\")\n",
    "sys.path.insert(1, \"/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/model\")\n",
    "from encoded_protein_dataset_new import get_embedding, EncodedProteinDataset_new, collate_fn_new#, dynamic_collate_fn\n",
    "from get_samples_potts import diverge, loglik_potts\n",
    "import torch, torchvision\n",
    "from potts_decoder import PottsDecoder\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from functools import partial\n",
    "import biotite.structure\n",
    "from biotite.structure.io import pdbx, pdb\n",
    "from biotite.structure.residues import get_residues\n",
    "from biotite.structure import filter_backbone\n",
    "from biotite.structure import get_chains\n",
    "from biotite.sequence import ProteinSequence\n",
    "from typing import Sequence, Tuple, List\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#import pytorch_warmup as warmup\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n",
    "\n",
    "##TURIN HPC\n",
    "#sys.path.insert(1, \"/Data/silva/esm/\")\n",
    "\n",
    "## EUROPA\n",
    "#sys.path.insert(1, \"/home/lucasilva/esm/\")\n",
    "\n",
    "##Lucas computer\n",
    "sys.path.insert(1, \"/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/esm/\")\n",
    "import esm\n",
    "#from esm.inverse_folding import util\n",
    "import esm.pretrained as pretrained\n",
    "from ioutils import read_fasta, read_encodings\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "from Bio import SeqIO\n",
    "\n",
    "#from dynamic_cluster_nce import dynamic_collate_fn, dynamic_cluster\n",
    "from dynamic_loader import dynamic_collate_fn, dynamic_cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter is:9 length data:9\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxh02.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1vwxh02_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/3o58E00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/3o58E00_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/2wc7A01.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/2wc7A01_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxP00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1vwxP00_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxG01.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1vwxG01_train.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxg01_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/3nskB00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/3nskB00_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1dosA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1dosA00_train.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1ivnA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/train/1ivnA00_train.a3m.pt\n",
      "No encoding file found for MSA file:  3o58e00_train.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxp00_train.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxH02_train.a3m.pt\n",
      "No encoding file found for MSA file:  3o58e00_test.a3m.pt\n",
      "No encoding file found for MSA file:  1vwxg01_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1vwxP00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/1vwxP00_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/1dosA00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/1dosA00_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/3nskB00.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/3nskB00_test.a3m.pt\n",
      "/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/2wc7A01.encodings.pt Mismatch in dimension, skipping /home/luchinoprince/split2/test/sequence/2wc7A01_test.a3m.pt\n",
      "Counter is:5819 length data:5791\r"
     ]
    }
   ],
   "source": [
    "### IDEA: MSAS PROCEDURE CAN GIVE DIFFERENT OUTPUT SHAPES? ASK\n",
    "max_msas = None\n",
    "#msa_dir = \"/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/msas/\"\n",
    "msa_dir = \"/home/luchinoprince/split2/\"\n",
    "encoding_dir =\"/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/structure_encodings/\"\n",
    "\n",
    "\n",
    "train_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'train'), encoding_dir, noise=0.02, max_msas=max_msas)          ## Default value of noise used\n",
    "sequence_test_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'test/sequence'), encoding_dir, noise=0.0, max_msas=max_msas)\n",
    "structure_test_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'test/structure'), encoding_dir, noise=0.0, max_msas=max_msas)\n",
    "superfamily_test_dataset = EncodedProteinDataset_new(os.path.join(msa_dir, 'test/superfamily'), encoding_dir, noise=0.0, max_msas=max_msas)\n",
    "\n",
    "print(f\"I have loaded the train and test datasets: train:{len(train_dataset)}, seq:{len(sequence_test_dataset)}, struc:{len(structure_test_dataset)}, super:{len(superfamily_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_structure_size = 2   ### I think with empty GPU we can go up to 16 easily\n",
    "perc_subset_test = 1.0     ## During the training, for every dataset available we select a random 10% of its samples\n",
    "batch_msa_size = 128 ### old is 32, original is 16\n",
    "q = 21 ##isn't always 21\n",
    "#dynamic_collate_fn\n",
    "\n",
    "collate_fn = partial(dynamic_collate_fn, q=q, batch_size=batch_structure_size, batch_msa_size=batch_msa_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_structure_size, collate_fn=collate_fn, shuffle=True,\n",
    "num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "sequence_test_loader = DataLoader(sequence_test_dataset, batch_size=batch_structure_size, collate_fn=collate_fn, shuffle=False, \n",
    "num_workers=4, pin_memory=True, sampler=RandomSampler(sequence_test_dataset, replacement=True, num_samples=int(perc_subset_test*len(sequence_test_dataset))))\n",
    "\n",
    "structure_test_loader = DataLoader(structure_test_dataset, batch_size=batch_structure_size, collate_fn=collate_fn, shuffle=False, \n",
    "num_workers=4, pin_memory=True, sampler=RandomSampler(structure_test_dataset, replacement=True, num_samples=int(perc_subset_test*len(structure_test_dataset))))\n",
    "\n",
    "superfamily_test_loader = DataLoader(superfamily_test_dataset, batch_size=batch_structure_size, collate_fn=collate_fn, shuffle=False, \n",
    "num_workers=4, pin_memory=True, sampler=RandomSampler(superfamily_test_dataset, replacement=True, num_samples=int(perc_subset_test*len(superfamily_test_dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(22, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = None\n",
    "embedding = None\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed = 24877\n",
    "torch.random.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "update_steps = 21000                                      ##Usual values are update steps=10^5, test_steps=10^2\n",
    "test_steps = 700\n",
    "bk_iter = False                                                  ## This tells us how ofter we save a model(default values is every ten-thousand updates)\n",
    "#n_epochs = update_steps//(len(train_dataset)//batch_structure_size)   ## the other update steps will be used for \"partial epochs\", I want to save the last complet epoch\n",
    "#print(f\"With update_steps:{update_steps} we will do {n_epochs} full epochs\")\n",
    "\n",
    "input_encoding_dim = 512\n",
    "param_embed_dim = 512\n",
    "n_param_heads = 48\n",
    "d_model = 512 ##old 512\n",
    "n_heads = 8 ## old 8\n",
    "n_layers = 6\n",
    "## Check before running which is the GPU which is free the most and put it as the running device\n",
    "device = 0        ## DON'T SET TO ONE OTHER THAN IN SPECIAL SPECIAL OCCASIONS, VERY NOISYYYYY!\n",
    "dropout = 0.1\n",
    "\n",
    "decoder = PottsDecoder(q, n_layers, d_model, input_encoding_dim, param_embed_dim, n_heads, n_param_heads, dropout=dropout)\n",
    "decoder.to(device)\n",
    "embedding = get_embedding(q)\n",
    "embedding.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_new(decoder, inputs, nsteps=1):\n",
    "    \"\"\"nsteps is the number of MC steps we take, default is 1 \"\"\"\n",
    "    msas, encodings, padding_mask  = [input.to(device, non_blocking=True) for input in inputs]\n",
    "    B, M, N = msas.shape\n",
    "    #print(f\"encodings' shape{encodings.shape}, padding mask:{padding_mask.shape}\")\n",
    "    param_embeddings, fields = decoder.forward_new(encodings, padding_mask)\n",
    "    llik_old = torch.mean(loglik_potts(param_embeddings, fields, embedding(msas)))\n",
    "    #llik_new = diverge(decoder, param_embeddings, fields, msas, embedding, padding_mask, steps=nsteps)\n",
    "    msas_new = diverge(decoder, param_embeddings, fields, msas, embedding, padding_mask, steps=nsteps)\n",
    "    llik_new = torch.mean(loglik_potts(param_embeddings, fields, embedding(msas_new)))\n",
    "    print(llik_new)\n",
    "    print(llik_old)\n",
    "    loss = llik_new - llik_old\n",
    "    print(loss)\n",
    "    return loss\n",
    "\n",
    "def get_loss_loader(decoder, loader, nsteps=1):\n",
    "    decoder.eval()\n",
    "    losses = []\n",
    "    #with torch.no_grad():\n",
    "    for effective_batch_size, inputs_packed in loader:\n",
    "        div_full = 0\n",
    "        for inputs in inputs_packed:\n",
    "            mini_batch_size = inputs[0].shape[0]\n",
    "            #_, npll = get_loss_indep(decoder, inputs, eta_J, eta_h) ## For independent model without couplings\n",
    "            div = get_loss_new(decoder, inputs, nsteps=nsteps).item()\n",
    "            div_full += div * mini_batch_size/effective_batch_size\n",
    "        losses.append(div_full)\n",
    "            #del inputs\n",
    "    \n",
    "    return np.mean(losses)\n",
    "\n",
    "def train(decoder, inputs_packed, optimizer, scaler, nsteps=1):\n",
    "    effective_batch_size = inputs_packed[0]\n",
    "    loss_div_full = 0\n",
    "    optimizer.zero_grad(set_to_none=True)                           ## set previous gradients to 0\n",
    "    with torch.cuda.amp.autocast():  ## autocasting mixed precision\n",
    "        for inputs in inputs_packed[1]:\n",
    "            mini_batch_size = inputs[0].shape[0]\n",
    "            div = get_loss_new(decoder, inputs, nsteps=nsteps)\n",
    "            div = div * mini_batch_size/effective_batch_size\n",
    "            ## Get gradients and accumulate them                      \n",
    "            scaler.scale(div).backward()\n",
    "            loss_div_full += div.detach()\n",
    "    \n",
    "    \n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    return loss_div_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21000 [00:00<?, ?it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 1, epoch: 1.00  train: 845.05, sequence: 847.91, structure: 727.00, superfamily: 756.51:   0%|          | 1/21000 [00:00<2:43:22,  2.14it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 2, epoch: 2.00  train: 917.53, sequence: 778.59, structure: 815.14, superfamily: 758.22:   0%|          | 2/21000 [00:00<2:43:17,  2.14it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 3, epoch: 3.00  train: 909.90, sequence: 800.49, structure: 674.85, superfamily: 774.08:   0%|          | 3/21000 [00:01<2:44:11,  2.13it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 4, epoch: 4.00  train: 806.31, sequence: 750.59, structure: 753.42, superfamily: 774.60:   0%|          | 4/21000 [00:01<2:43:39,  2.14it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 5, epoch: 5.00  train: 855.63, sequence: 731.05, structure: 621.04, superfamily: 786.02:   0%|          | 5/21000 [00:02<2:43:28,  2.14it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 6, epoch: 6.00  train: 837.94, sequence: 839.51, structure: 806.75, superfamily: 671.38:   0%|          | 6/21000 [00:02<2:41:47,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 7, epoch: 7.00  train: 874.47, sequence: 829.26, structure: 688.82, superfamily: 737.26:   0%|          | 7/21000 [00:03<2:40:58,  2.17it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 8, epoch: 8.00  train: 860.48, sequence: 807.42, structure: 736.60, superfamily: 788.12:   0%|          | 8/21000 [00:03<2:40:23,  2.18it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 9, epoch: 9.00  train: 902.44, sequence: 731.80, structure: 543.06, superfamily: 603.44:   0%|          | 9/21000 [00:04<2:40:47,  2.18it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 10, epoch: 10.00  train: 750.31, sequence: 629.89, structure: 542.22, superfamily: 592.53:   0%|          | 10/21000 [00:04<2:42:09,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 11, epoch: 11.00  train: 641.99, sequence: 489.94, structure: 494.63, superfamily: 473.60:   0%|          | 11/21000 [00:05<2:42:30,  2.15it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 12, epoch: 12.00  train: 593.31, sequence: 440.26, structure: 356.23, superfamily: 380.61:   0%|          | 12/21000 [00:05<2:42:35,  2.15it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 13, epoch: 13.00  train: 406.04, sequence: 323.59, structure: 324.97, superfamily: 311.21:   0%|          | 13/21000 [00:06<2:42:57,  2.15it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 14, epoch: 14.00  train: 352.68, sequence: 264.85, structure: 217.59, superfamily: 226.60:   0%|          | 14/21000 [00:06<2:41:51,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 15, epoch: 15.00  train: 284.14, sequence: 192.42, structure: 200.46, superfamily: 180.14:   0%|          | 15/21000 [00:06<2:42:07,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 16, epoch: 16.00  train: 208.21, sequence: 143.59, structure: 137.03, superfamily: 153.45:   0%|          | 16/21000 [00:07<2:42:14,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 17, epoch: 17.00  train: 170.53, sequence: 104.43, structure: 129.97, superfamily: 132.60:   0%|          | 17/21000 [00:07<2:41:48,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 18, epoch: 18.00  train: 132.26, sequence: 71.68, structure: 94.60, superfamily: 89.07:   0%|          | 18/21000 [00:08<2:41:52,  2.16it/s]   /home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 19, epoch: 19.00  train: 90.55, sequence: 47.33, structure: 66.87, superfamily: 70.07:   0%|          | 19/21000 [00:08<2:41:53,  2.16it/s] /home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 20, epoch: 20.00  train: 68.32, sequence: 8.61, structure: 48.56, superfamily: 49.41:   0%|          | 20/21000 [00:09<2:42:00,  2.16it/s] /home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 21, epoch: 21.00  train: 31.58, sequence: -31.21, structure: 28.62, superfamily: 34.87:   0%|          | 21/21000 [00:09<2:41:46,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 22, epoch: 22.00  train: 5.70, sequence: -63.84, structure: 5.11, superfamily: 16.24:   0%|          | 22/21000 [00:10<2:41:29,  2.17it/s]  /home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 23, epoch: 23.00  train: -17.21, sequence: -112.89, structure: -15.86, superfamily: 4.67:   0%|          | 23/21000 [00:10<2:42:21,  2.15it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 24, epoch: 24.00  train: -59.70, sequence: -125.52, structure: -33.94, superfamily: -21.01:   0%|          | 24/21000 [00:11<2:41:50,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 25, epoch: 25.00  train: -83.13, sequence: -240.82, structure: -51.42, superfamily: -23.55:   0%|          | 25/21000 [00:11<2:42:08,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 26, epoch: 26.00  train: -121.31, sequence: -271.22, structure: -69.41, superfamily: -25.47:   0%|          | 26/21000 [00:12<2:42:08,  2.16it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 27, epoch: 27.00  train: -199.56, sequence: -312.51, structure: -124.20, superfamily: -55.66:   0%|          | 27/21000 [00:12<2:42:17,  2.15it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 28, epoch: 28.00  train: -184.53, sequence: -429.11, structure: -161.74, superfamily: -74.12:   0%|          | 28/21000 [00:12<2:42:41,  2.15it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 29, epoch: 29.00  train: -274.54, sequence: -644.43, structure: -201.74, superfamily: -106.62:   0%|          | 29/21000 [00:13<2:43:20,  2.14it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 30, epoch: 30.00  train: -375.41, sequence: -664.90, structure: -271.41, superfamily: -93.79:   0%|          | 30/21000 [00:13<2:43:28,  2.14it/s] /home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 31, epoch: 31.00  train: -473.78, sequence: -744.86, structure: -211.61, superfamily: -113.77:   0%|          | 31/21000 [00:14<2:42:32,  2.15it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 32, epoch: 32.00  train: -428.20, sequence: -922.03, structure: -328.72, superfamily: -145.10:   0%|          | 32/21000 [00:14<2:43:54,  2.13it/s]/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n",
      "update_step: 32, epoch: 32.00  train: -428.20, sequence: -922.03, structure: -328.72, superfamily: -145.10:   0%|          | 32/21000 [00:15<2:47:30,  2.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m     structure_test_loss \u001b[39m=\u001b[39m get_loss_loader(decoder, structure_test_loader, nsteps\u001b[39m=\u001b[39mnsteps)\n\u001b[1;32m     43\u001b[0m     \u001b[39m#print(\"Completed second test\")\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     superfamily_test_loss \u001b[39m=\u001b[39m get_loss_loader(decoder, superfamily_test_loader, nsteps\u001b[39m=\u001b[39;49mnsteps)\n\u001b[1;32m     45\u001b[0m     \u001b[39m#print(\"Completed third test\")\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[39m#summary_writer.add_scalar('loss/train', train_loss, update_step)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m#summary_writer.add_scalar('loss/superfamily', superfamily_test_loss, update_step)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m                 \u001b[39m## UNCOMMENT THIS!\u001b[39;00m\n\u001b[1;32m     52\u001b[0m train_batch_losses \u001b[39m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m, in \u001b[0;36mget_loss_loader\u001b[0;34m(decoder, loader, nsteps)\u001b[0m\n\u001b[1;32m     16\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m \u001b[39m#with torch.no_grad():\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfor\u001b[39;00m effective_batch_size, inputs_packed \u001b[39min\u001b[39;00m loader:\n\u001b[1;32m     19\u001b[0m     div_full \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     20\u001b[0m     \u001b[39mfor\u001b[39;00m inputs \u001b[39min\u001b[39;00m inputs_packed:\n",
      "File \u001b[0;32m~/anaconda3/envs/IF/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/IF/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1318\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \n\u001b[1;32m   1323\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/IF/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1425\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[39m# Send something to pin_memory_thread in case it is waiting\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \u001b[39m# so that it can wake up and check `pin_memory_thread_done_event`\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_result_queue\u001b[39m.\u001b[39mput((\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m-> 1425\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pin_memory_thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m   1426\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_result_queue\u001b[39m.\u001b[39mcancel_join_thread()\n\u001b[1;32m   1427\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_result_queue\u001b[39m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#summary_writer = SummaryWriter(log_dir='runs/indep_model')#log_dir=logdir)\n",
    "#summary_writer = SummaryWriter(log_dir='./runs_CD/')\n",
    "layout = {\n",
    "    \"metrics\": {\n",
    "        \"loss\": [\"Multiline\", [\"loss/train\", \"loss/sequence\", \"loss/structure\", \"loss/superfamily\"]],}\n",
    "}\n",
    "#summary_writer.add_custom_scalars(layout)\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr)\n",
    "\n",
    "nsteps=10\n",
    "\n",
    "start = time.time()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "with tqdm(total = update_steps) as pbar: ##This is used to have the nice loading bar while training\n",
    "    train_loss = 0\n",
    "    update_step = 0\n",
    "    max_gpu=0\n",
    "    train_batch_losses = []\n",
    "    epoch = 0.0\n",
    "    while update_step < update_steps:\n",
    "        for inputs_packed in train_loader:\n",
    "            decoder.train()\n",
    "\n",
    "            div_full = train(decoder, inputs_packed, optimizer, scaler, nsteps=nsteps)\n",
    "            div_full.detach()\n",
    "            #optimizer.step()                                ## Do a step of GD\n",
    "            update_step += 1                                ## Increase update step (the update steps will count also different batches within the same epoch)\n",
    "            epoch = update_step / len(train_loader)\n",
    "            \n",
    "            train_batch_losses.append(div_full.item()) ## Here we append the lossess in the different batches within the same epoch\n",
    "            \n",
    "            ## We want to keep track of the test loss not at every batch, too costrly otherwise. Usually set to once every 100.\n",
    "            if (update_step == 1) or (epoch % 1 == 0):\n",
    "                #check_aux = train_batch_losses.copy()\n",
    "                #print(check_aux)\n",
    "                train_loss = np.mean(train_batch_losses)\n",
    "                with torch.no_grad():\n",
    "                    #print(\"beginning first test\")\n",
    "                    sequence_test_loss = get_loss_loader(decoder, sequence_test_loader, nsteps=nsteps)\n",
    "                    #print(\"Completed first test\")\n",
    "                    structure_test_loss = get_loss_loader(decoder, structure_test_loader, nsteps=nsteps)\n",
    "                    #print(\"Completed second test\")\n",
    "                    superfamily_test_loss = get_loss_loader(decoder, superfamily_test_loader, nsteps=nsteps)\n",
    "                    #print(\"Completed third test\")\n",
    "\n",
    "                #summary_writer.add_scalar('loss/train', train_loss, update_step)\n",
    "                #summary_writer.add_scalar('loss/sequence', sequence_test_loss, update_step)\n",
    "                #summary_writer.add_scalar('loss/structure', structure_test_loss, update_step)\n",
    "                #summary_writer.add_scalar('loss/superfamily', superfamily_test_loss, update_step)\n",
    "                                ## UNCOMMENT THIS!\n",
    "                train_batch_losses = []\n",
    "\n",
    "        \n",
    "            pbar.set_description(f'update_step: {update_step}, epoch: {epoch:.2f}  train: {train_loss:.2f}, sequence: {sequence_test_loss:.2f}, structure: {structure_test_loss:.2f}, superfamily: {superfamily_test_loss:.2f}')\n",
    "            pbar.update(1)\n",
    "\n",
    "print(f\"It took {time.time()-start} seconds\")\n",
    "save_metrics = {'loss/train': train_loss, 'loss/sequence': sequence_test_loss, \n",
    "'loss/structure': structure_test_loss, 'loss/superfamily': superfamily_test_loss}\n",
    "#summary_writer.add_hparams(hyperparams, save_metrics)\n",
    "#summary_writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us create a small code that I can deal with easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  1\n",
      "tensor([[20, 20, 20, 20, 20],\n",
      "        [20, 20, 20, 19,  2],\n",
      "        [ 2,  4,  3,  9, 12],\n",
      "        [ 2,  4,  6, 20,  2],\n",
      "        [ 2,  4,  0,  9, 15]], dtype=torch.int32)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  2\n",
      "tensor([[20, 20, 20, 20, 20],\n",
      "        [20, 20, 20, 20, 16],\n",
      "        [ 2,  4,  0,  9, 11],\n",
      "        [20, 20, 20, 20, 20],\n",
      "        [20, 20, 20, 19,  2]], dtype=torch.int32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iterator=0\n",
    "while iterator < 2:\n",
    "    for inputs_packed in train_loader:\n",
    "        iterator+=1\n",
    "        print(\"Iter: \",iterator)\n",
    "        print(inputs_packed[1][0][0][0,0:5,0:5])\n",
    "        print(\"\\n\")\n",
    "    #decoder.train()\n",
    "    #div_full = train(decoder, inputs_packed, optimizer, scaler, nsteps=nsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/InverseFolding/util/encoded_protein_dataset_new.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encodings = torch.tensor(read_encodings(encoding_path, trim=False))\n"
     ]
    }
   ],
   "source": [
    "inputs_packed_saved = []\n",
    "it = 0\n",
    "for inputs_packed in train_loader:\n",
    "    inputs_packed_saved = inputs_packed\n",
    "    it+=1\n",
    "    if it > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 264, 119])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_packed_saved[1][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_packed[1][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "tensor(-51.1993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-51.6796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4803, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  1\n",
      "tensor(-50.5598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-51.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.9515, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  2\n",
      "tensor(-50.6039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-51.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5465, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  3\n",
      "tensor(-51.1805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-51.5513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3707, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  4\n",
      "tensor(-40.4442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-40.7716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3275, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  5\n",
      "tensor(-39.9087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-40.0111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1024, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  6\n",
      "tensor(-40.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-40.3752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.3017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  7\n",
      "tensor(-35.1830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-34.5828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.6002, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  8\n",
      "tensor(-37.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-35.8918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1.1085, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  9\n",
      "tensor(-59.9666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-58.3301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1.6364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  10\n",
      "tensor(-90.4664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-88.3578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2.1086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  11\n",
      "tensor(-128.4419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-125.3130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-3.1289, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  12\n",
      "tensor(-180.0830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-175.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-4.9747, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  13\n",
      "tensor(-244.6988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-239.1042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-5.5947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  14\n",
      "tensor(-330.1536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-321.8754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-8.2782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  15\n",
      "tensor(-433.8409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-424.3275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-9.5134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  16\n",
      "tensor(-567.7157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-554.9130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-12.8027, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  17\n",
      "tensor(-708.0878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-691.4613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-16.6265, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  18\n",
      "tensor(-859.0895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-840.3883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-18.7012, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  19\n",
      "tensor(-1019.3452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-998.1157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-21.2296, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  20\n",
      "tensor(-1188.5417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1169.8002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-18.7416, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  21\n",
      "tensor(-1383.0840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1354.1482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-28.9358, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  22\n",
      "tensor(-1616.6173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1579.0233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-37.5940, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  23\n",
      "tensor(-1623.0770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1585.4922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-37.5848, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  24\n",
      "tensor(-1885.0536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1852.6993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-32.3542, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  25\n",
      "tensor(-2158.8518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2119.5979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-39.2539, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  26\n",
      "tensor(-2496.2239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2447.9382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-48.2856, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  27\n",
      "tensor(-2884.1797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2815.6472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-68.5325, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  28\n",
      "tensor(-3261.9612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-3193.3813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-68.5798, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  29\n",
      "tensor(-3679.5791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-3599.8977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-79.6814, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  30\n",
      "tensor(-4141.7559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-4054.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-87.4585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  31\n",
      "tensor(-4643.3667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-4541.2134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-102.1533, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  32\n",
      "tensor(-5203.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-5097.3877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-105.9185, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  33\n",
      "tensor(-5936.0342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-5802.9526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-133.0815, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  34\n",
      "tensor(-6704.6558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-6538.3984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-166.2573, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  35\n",
      "tensor(-7483.2241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-7337.5601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-145.6641, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  36\n",
      "tensor(-7507.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-7335.4556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-172.0996, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  37\n",
      "tensor(-8406.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-8241.4297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-165.1504, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  38\n",
      "tensor(-9373.4570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-9177.4287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-196.0283, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  39\n",
      "tensor(-10426.6514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-10194.6631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-231.9883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  40\n",
      "tensor(-11670.3447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-11410.5859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-259.7588, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  41\n",
      "tensor(-13040.6787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-12728.7441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-311.9346, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  42\n",
      "tensor(-14556.2314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-14256.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-299.6514, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  43\n",
      "tensor(-16241.6992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-15889.7334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-351.9658, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  44\n",
      "tensor(-17906.5469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-17576.0234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-330.5234, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  45\n",
      "tensor(-19836.2734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-19355.2969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-480.9766, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  46\n",
      "tensor(-19823.2852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-19387.9023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-435.3828, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  47\n",
      "tensor(-21890.8164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-21456.0527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-434.7637, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  48\n",
      "tensor(-24267.8828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-23747.5996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-520.2832, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  49\n",
      "tensor(-26663.4668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-26169.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-494.3145, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  50\n",
      "tensor(-29225.9180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-28752.7012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-473.2168, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  51\n",
      "tensor(-31974.1484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-31374.4531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-599.6953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  52\n",
      "tensor(-35185.5781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-34466.7812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-718.7969, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  53\n",
      "tensor(-38540.9922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-37779.7070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-761.2852, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  54\n",
      "tensor(-42183.3789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-41351.9766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-831.4023, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  55\n",
      "tensor(-46233.7305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-45205.0156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1028.7148, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  56\n",
      "tensor(-50567.3594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-49553.4727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1013.8867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  57\n",
      "tensor(-55090.1602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-54047.3203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1042.8398, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  58\n",
      "tensor(-59926.0586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-58887.4961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1038.5625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  59\n",
      "tensor(-60127.5352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-58949.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1178.2891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  60\n",
      "tensor(-65493.5156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-64178.5000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1315.0156, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  61\n",
      "tensor(-71258.9922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-69734.2734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1524.7188, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  62\n",
      "tensor(-77143.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-75389.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1754.0859, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  63\n",
      "tensor(-82870.5000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-81345.3438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1525.1562, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  64\n",
      "tensor(-89332.4844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-87719.3984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1613.0859, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  65\n",
      "tensor(-96426.4766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-94486.2266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1940.2500, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  66\n",
      "tensor(-103630.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-101811.8828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1818.3359, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  67\n",
      "tensor(-111330.2031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-109435.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-1894.8984, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  68\n",
      "tensor(-119619.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-117235.3438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2383.9609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  69\n",
      "tensor(-128670.2891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-126154.4609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2515.8281, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  70\n",
      "tensor(-138468.2344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-135558.9375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2909.2969, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  71\n",
      "tensor(-138344.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-135487.7656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2856.2656, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  72\n",
      "tensor(-148385.6562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-145520.4844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2865.1719, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  73\n",
      "tensor(-160245.6250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-156695.8281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-3549.7969, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  74\n",
      "tensor(-171220.2344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-168606.2656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-2613.9688, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  75\n",
      "tensor(-184550.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-181013.9844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-3536.0469, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  76\n",
      "tensor(-198612.7031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-194645.8906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-3966.8125, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  77\n",
      "tensor(-213304.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-209481.5469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-3822.6719, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  78\n",
      "tensor(-229660.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-225175.4844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-4484.9219, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  79\n",
      "tensor(-245963.8125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-241759.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-4204.4375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  80\n",
      "tensor(-265676.1875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-259400.9844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-6275.2031, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  81\n",
      "tensor(-284818.4375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-278912.8438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-5905.5938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  82\n",
      "tensor(-304508.0938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-299043.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-5464.6875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  83\n",
      "tensor(-327102.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-320336.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-6765.7500, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  84\n",
      "tensor(-350281.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-342779.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-7502.3750, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  85\n",
      "tensor(-349827.6250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-342814.2812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-7013.3438, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  86\n",
      "tensor(-374541.0625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-366454.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-8086.0938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  87\n",
      "tensor(-399653.0938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-392103.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-7550.0625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  88\n",
      "tensor(-427358.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-419447.4688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-7910.6562, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  89\n",
      "tensor(-456099.5938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-447877.6250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-8221.9688, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  90\n",
      "tensor(-487100.5000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-478316.1562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-8784.3438, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  91\n",
      "tensor(-518458.8125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-509677.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-8780.8438, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  92\n",
      "tensor(-552104.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-541455.0625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-10649.0625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  93\n",
      "tensor(-586008.4375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-575532.3125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-10476.1250, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  94\n",
      "tensor(-622653.0625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-611625.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-11027.9375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  95\n",
      "tensor(-660646.9375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-649671.5625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-10975.3750, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  96\n",
      "tensor(-702420.6250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-690789.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-11630.9375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  97\n",
      "tensor(-749126.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-734470.1875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-14656.1875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  98\n",
      "tensor(-797222.4375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-781031.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-16190.7500, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n",
      "Iteration:  99\n",
      "tensor(-846083.1875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-831803.8125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-14279.3750, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr)\n",
    "\n",
    "nsteps=2\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "#for it in \n",
    "for it in range(100):\n",
    "    print(\"Iteration: \", it)\n",
    "    div_full = train(decoder, inputs_packed_saved, optimizer, scaler, nsteps=nsteps)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8441, 0.3777, 0.9687, 0.6552, 0.9464, 0.5977, 0.2007, 0.8219, 0.5615,\n",
       "        0.7690], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
