{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comprehensive-respect",
   "metadata": {},
   "source": [
    "In this notebook I will implementing the new decoder module discussed with _Christoph_. From the encodings given by the __ESM__ encoder we begin by attaching two layers of standard _Multi-Head self-attention_ which we then train by minimising the _pseudo-likelihhod_(find package).\n",
    "Remember that from here we assume to be working with tensors, not graphs anymore. Our hope is that all of the relevant information coming from the graph structure has already been encoded in the embeddings of the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "physical-offense",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luchino_prince/opt/anaconda3/envs/Modern_Applied_ML/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn import TransformerEncoderLayer, Linear\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import one_hot\n",
    "import pickle\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a2567f-0d56-49a7-a015-d8c250d02fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I think I have to be carefull at the dimensions of the objects\n",
    "class Potts_Decoder(torch.nn.Module):\n",
    "    def __init__(self, n_cat:int, n_layers:int, atten_dim:int, embed_dim:int, n_heads:int, dropout=0.0):\n",
    "        ## We use the init of the superclass Module\n",
    "        super().__init__()\n",
    "        #self.system_size = system_size       ##length of the amino-acid\n",
    "        self.n_cat = n_cat                   ## for proteins this is 21, fix??\n",
    "        self.n_layers = n_layers\n",
    "        self.atten_dim = atten_dim           ## this is the input dimension for the attention layer\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.attentions = torch.nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.attentions.append(TransformerEncoderLayer(self.atten_dim, self.n_heads,\n",
    "                                   dropout=self.dropout))\n",
    "        ## Maybe add a Linear Layer (usually always done)\n",
    "        self.Linear = Linear(self.atten_dim, self.n_cat*self.embed_dim) ##21 is the number of amino-acids + skip character\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        ## I have to provide a masking matrix\n",
    "        ## For the moment suppose a single protein.\n",
    "        L = x.shape[0]\n",
    "        ## If we have a batch of proteins, for the transformer, is this a batch of batches??\n",
    "        for attention in self.attentions:\n",
    "            x = attention(x).relu()\n",
    "        \n",
    "        ## We have to output a matrix, not a vector, we hence do the opposite of CNNs\n",
    "        x = self.Linear(x).reshape(L, self.n_cat, self.embed_dim)\n",
    "        #coupling = x.reshape(L, 1, 21, self.embed_dim) @ torch.transpose(x, 1, 2).reshape(1, L, self.embed_dim, 21)\n",
    "        #coupling = torch.transpose(coupling, 1, 2).reshape(L*21, L*21) ##check whether this is correct, looks yes\n",
    "        coupling = torch.flatten(x, end_dim=1) @ torch.flatten(torch.transpose(torch.transpose(x, 2, 0), 1, 2), \n",
    "                                                               start_dim=1)\n",
    "        fields = torch.diag(coupling).reshape(L, self.n_cat)\n",
    "        coupling = coupling * mask     ##element-wise product\n",
    "        #coupling = 0.5*(coupling + torch.transpose(coupling,0,1))\n",
    "        \n",
    "        ##This recovers the overall coupling matrix\n",
    "        coupling = coupling + torch.transpose(coupling, 0, 1)\n",
    "        #for i in range(L):\n",
    "        #    coupling[i*self.n_cat : (i+1)*self.n_cat, i*self.n_cat : (i+1)*self.n_cat] = 0.0    \n",
    "        \n",
    "        return fields, coupling \n",
    "    \n",
    "    \n",
    "    \n",
    "def Pseudo_Likelihood(model, data:Tensor, fields:Tensor, coupling:Tensor, one_hot_input:bool = False) -> Tensor:\n",
    "    seq = data[0]\n",
    "    if not one_hot_input:\n",
    "        data = one_hot(data, num_classes = model.n_cat).float().view(data.shape[0], -1)\n",
    "    return torch.mean(torch.logsumexp(energy_diffs(model, data, fields, coupling, one_hot_input=True), dim=-1), axis=-1)    \n",
    "\n",
    "def Local_Fields(model, data: Tensor, fields:Tensor, coupling:Tensor, one_hot_input: bool = False) -> Tensor:\n",
    "    ndata: int = data.shape[0]\n",
    "    system_size = coupling.shape[0]//model.n_cat\n",
    "    if not one_hot_input:\n",
    "        data = one_hot(data, num_classes = model.n_cat).float().view(data.shape[0], -1)\n",
    "    return data.float() @ coupling + fields.T.reshape(1, -1).expand(ndata, system_size*model.n_cat) \n",
    "\n",
    "def energy_diffs(model, data: Tensor, fields:Tensor, coupling:Tensor, one_hot_input: bool = False) -> Tensor:\n",
    "\n",
    "    ndata: int = data.shape[0]\n",
    "    system_size = coupling.shape[0]//model.n_cat\n",
    "    if not one_hot_input:\n",
    "        data = one_hot(data, num_classes = model.n_cat).float().view(data.shape[0], -1)\n",
    "    ## We extract the local fields vector\n",
    "    local_fields: Tensor = Local_Fields(model, data, fields, coupling, one_hot_input=True)\n",
    "    \n",
    "    ## torch.mul is element-wise product\n",
    "    local_fields_with_deltas: Tensor = torch.mul(local_fields, data)\n",
    "    local_fields_with_deltas = local_fields_with_deltas.reshape(ndata, system_size, model.n_cat)\n",
    "    local_fields_true: Tensor = torch.sum(local_fields_with_deltas, axis=-1)\n",
    "    local_fields_true = local_fields_true.unsqueeze(-1).expand(ndata, system_size, model.n_cat)\n",
    "    energy_diffs: Tensor = local_fields_true - local_fields.reshape(ndata, system_size, model.n_cat) \n",
    "    return -1*energy_diffs\n",
    "\n",
    "def energy_diffs_position(model, position: int, data: Tensor, fields:Tensor, coupling:Tensor, one_hot_input: bool = False) -> Tensor:\n",
    "\n",
    "    if not one_hot_input:\n",
    "        data = one_hot(data, num_classes = model.n_cat).float().view(data.shape[0], -1)\n",
    "\n",
    "    energy_diffs: Tensor = energy_diffs(model, data, fields, coupling, one_hot_input=True)\n",
    "    ##position is the amino acid position \n",
    "    return energy_diffs[:, position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quantitative-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "right-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_to_num = {'C': 4, 'D': 3, 'S': 15, 'Q': 5, 'K': 11, 'I': 9,\n",
    "                       'P': 14, 'T': 16, 'F': 13, 'A': 0, 'G': 7, 'H': 8,\n",
    "                       'E': 6, 'L': 10, 'R': 1, 'W': 17, 'V': 19, \n",
    "                       'N': 2, 'Y': 18, 'M': 12, 'X':20}\n",
    "# 'X' I think is -\n",
    "## got this conversion from GVP github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c6a823-d7a5-4317-ba30-322d5ac314ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoded_Proteins(Dataset):\n",
    "    def __init__(self, path_dir, transform=None, target_transform=None):\n",
    "        self.path_dir = path_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(path_dir))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #protein_path = self.path_dir + '/CATH_430_' + str(idx) \n",
    "        protein_file = os.path.join(self.path_dir, os.listdir(self.path_dir)[idx])\n",
    "        d = load_obj(protein_file)\n",
    "        encoded_protein = d['Encoded_Protein']\n",
    "        #native_seq = d['Native_Seq']\n",
    "        num_seq = d['Num_Seq']\n",
    "        if self.transform:\n",
    "            encoded_protein = self.transform(encoded_protein)\n",
    "        if self.target_transform:\n",
    "            native_seq = self.target_transform(native_seq)\n",
    "        return encoded_protein, num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f885dac-9721-4975-9fc6-4738a248ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_collate(batch):\n",
    "    \"\"\"\n",
    "    Fill in\n",
    "    \"\"\"\n",
    "    #item = batch[0]\n",
    "    #print(item)\n",
    "    \n",
    "    data_x = [item[0] for item in batch]\n",
    "    data_y = [item[1] for item in batch]\n",
    "    # each element is of size (1, h*, w*). where (h*, w*) changes from mask to another.\n",
    "    ## data_y is already numerical\n",
    "    return data_x, data_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c7748d1-d62c-46c1-8477-815dcb70b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_dir = \"C:/Users/lucas/Desktop/Encoded_Proteins_Toy\"\n",
    "path_dir = \"./Encoded_Proteins_Toy/\"\n",
    "dataset = Encoded_Proteins(path_dir)\n",
    "#dataloader = DataLoader(dataset, batch_size=4, collate_fn=default_collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cc413a2-39e6-438d-9d86-ac043c6d5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Subset(dataset, np.arange(1000))\n",
    "dataset_test = Subset(dataset, np.arange(start=1000, stop=1300))\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=4, collate_fn=default_collate, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=4, collate_fn=default_collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6cf3cc2-f699-4698-891e-f985fce10c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader(sample_ds, batch_size=4, collate_fn=default_collate, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ca1157b-7d93-48b7-bd41-5c41266caaf6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterator:2\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m mask: Tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(mask, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m##We have to change how we save the output... necessarely\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m fields, couplings \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#fields, couplings = decoder(data_x)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#seq_vals=torch.zeros(len(data_y), dtype=int)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#for char,idx in zip(data_y, range(len(data_y))):\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#    seq_vals[idx] = letter_to_num[char]\u001b[39;00m\n\u001b[1;32m     43\u001b[0m hot \u001b[38;5;241m=\u001b[39m one_hot(data_y, num_classes\u001b[38;5;241m=\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mn_cat)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Modern_Applied_ML/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mPotts_Decoder.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     38\u001b[0m coupling \u001b[38;5;241m=\u001b[39m coupling \u001b[38;5;241m*\u001b[39m mask     \u001b[38;5;66;03m##element-wise product\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#coupling = 0.5*(coupling + torch.transpose(coupling,0,1))\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m##This recovers the overall coupling matrix\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m coupling \u001b[38;5;241m=\u001b[39m \u001b[43mcoupling\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoupling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#for i in range(L):\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#    coupling[i*self.n_cat : (i+1)*self.n_cat, i*self.n_cat : (i+1)*self.n_cat] = 0.0    \u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fields, coupling\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#system_size:int = data.shape[0]\n",
    "n_cat:int = 21\n",
    "n_layers:int=2\n",
    "atten_dim:int=512\n",
    "embed_dim:int=5\n",
    "n_heads:int=16\n",
    "batch_size:int=4\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=default_collate, shuffle=True)\n",
    "\n",
    "#decoder = Potts_Decoder(system_size, n_cat, n_layers, atten_dim, embed_dim, n_heads).to(device)\n",
    "lr = 0.001\n",
    "\n",
    "logging = []\n",
    "#device='cuda'\n",
    "device='cpu'\n",
    "#optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "decoder = Potts_Decoder(n_cat, n_layers, atten_dim, embed_dim, n_heads).to(device)\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "loss_f = Pseudo_Likelihood\n",
    "\n",
    "num_epochs = 10\n",
    "decoder.train()\n",
    "## Set the decoder to training mode\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    total_loss = 0\n",
    "    iterator=0\n",
    "    for data_xs, data_ys in dataloader_train:\n",
    "        print(f\"iterator:{iterator}\", end=\"\\r\")\n",
    "        iterator+=1\n",
    "        for data_x, data_y in zip(data_xs, data_ys):\n",
    "            data_x = data_x.to(device)\n",
    "            system_size=data_x.shape[0]\n",
    "            mask: Tensor = torch.triu(torch.ones(system_size*decoder.n_cat, system_size*decoder.n_cat, dtype=bool), 1)  \n",
    "            for i in range(system_size):\n",
    "                mask[i*n_cat : (i+1)*n_cat, i*n_cat : (i+1)*n_cat] = 0              \n",
    "            mask: Tensor = torch.nn.Parameter(mask, requires_grad=False).to(device)\n",
    "            ##We have to change how we save the output... necessarely\n",
    "            fields, couplings = decoder(data_x, mask)\n",
    "            #fields, couplings = decoder(data_x)\n",
    "            #seq_vals=torch.zeros(len(data_y), dtype=int)\n",
    "            #for char,idx in zip(data_y, range(len(data_y))):\n",
    "            #    seq_vals[idx] = letter_to_num[char]\n",
    "            hot = one_hot(data_y, num_classes=decoder.n_cat)\n",
    "            hot = torch.flatten(hot).unsqueeze(dim=0).to(device)\n",
    "            #print(system_size)\n",
    "\n",
    "            loss = loss_f(decoder, hot, fields, couplings, one_hot_input=True)/batch_size\n",
    "            total_loss += float(loss)\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"We are at epoch:{epoch}, loss is:{total_loss}\", end=\"\\r\")\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    #################################### TESTING #########################################\n",
    "    total_loss_test = 0\n",
    "    model.eval()\n",
    "    for data_xs, data_ys in dataloader_test:\n",
    "        for data_x, data_y in zip(data_xs, data_ys):\n",
    "            data_x = data_x.to(device)\n",
    "            system_size=data_x.shape[0]\n",
    "            mask: Tensor = torch.triu(torch.ones(system_size*decoder.n_cat, system_size*decoder.n_cat, dtype=bool), 1)  \n",
    "            for i in range(system_size):\n",
    "                mask[i*n_cat : (i+1)*n_cat, i*n_cat : (i+1)*n_cat] = 0              \n",
    "            mask: Tensor = torch.nn.Parameter(mask, requires_grad=False).to(device)\n",
    "            ##We have to change how we save the output... necessarely\n",
    "            fields, couplings = decoder(data_x, mask)\n",
    "            #fields, couplings = decoder(data_x)\n",
    "            #seq_vals=torch.zeros(len(data_y), dtype=int)\n",
    "            #for char,idx in zip(data_y, range(len(data_y))):\n",
    "            #    seq_vals[idx] = letter_to_num[char]\n",
    "            hot = one_hot(data_y, num_classes=decoder.n_cat)\n",
    "            hot = torch.flatten(hot).unsqueeze(dim=0).to(device)\n",
    "            #print(system_size)\n",
    "\n",
    "            loss = loss_f(decoder, hot, fields, couplings, one_hot_input=True)/batch_size\n",
    "            total_loss_test += float(loss)\n",
    "    \n",
    "    #train_acc = test(train_loader)\n",
    "    #test_acc = test(test_loader)\n",
    "    #logging.append({\"Epoch\": epoch, \"value\": total_loss, \"kind\": \"Loss\"})\n",
    "    #logging.append({\"Epoch\": epoch, \"value\": train_acc, \"kind\": \"Train_acc\"})\n",
    "    #logging.append({\"Epoch\": epoch, \"value\": test_acc, \"kind\": \"Test\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88501e-375d-417e-96e3-03fde6f109f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
