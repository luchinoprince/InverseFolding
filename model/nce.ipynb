{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook I will try to implement the loss of the Negative Contrastive estimation. \n",
    "\n",
    "Notice that eventually we will also have to change the model to add the parameters of the normalising constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "\n",
    "sys.path.insert(1, \"./../util\")\n",
    "sys.path.insert(1, \"./../model\")\n",
    "from encoded_protein_dataset_new import get_embedding, EncodedProteinDataset_new, collate_fn_new#, dynamic_collate_fn\n",
    "from pseudolikelihood import get_npll2, get_npll_indep\n",
    "import torch, torchvision\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from potts_decoder_nce import PottsDecoder\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from functools import partial\n",
    "import biotite.structure\n",
    "from biotite.structure.io import pdbx, pdb\n",
    "from biotite.structure.residues import get_residues\n",
    "from biotite.structure import filter_backbone\n",
    "from biotite.structure import get_chains\n",
    "from biotite.sequence import ProteinSequence\n",
    "from typing import Sequence, Tuple, List\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#import pytorch_warmup as warmup\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n",
    "\n",
    "##TURIN HPC\n",
    "#sys.path.insert(1, \"/Data/silva/esm/\")\n",
    "\n",
    "## EUROPA\n",
    "#sys.path.insert(1, \"/home/lucasilva/esm/\")\n",
    "\n",
    "##Lucas computer\n",
    "sys.path.insert(1, \"/home/luchinoprince/Dropbox/Old_OneDrive/Phd/Second_year/research/Feinauer/esm/\")\n",
    "import esm\n",
    "#from esm.inverse_folding import util\n",
    "import esm.pretrained as pretrained\n",
    "from ioutils import read_fasta, read_encodings\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "B=3\n",
    "N=6\n",
    "q=21\n",
    "M=20\n",
    "\n",
    "encodings = torch.randn((B, N, 512))\n",
    "#encodings = 0.1 * torch.ones((B, N, 512))\n",
    "msas = torch.randint(low=0, high=21, size=(B,M,N))\n",
    "\n",
    "embeddings = get_embedding(q)\n",
    "msas_embedded = embeddings(msas)\n",
    "#padding_mask = torch.zeros(size=(B, N),dtype=bool)\n",
    "padding_mask = torch.randint(low=0, high=2, size=(B,N), dtype=bool)\n",
    "padding_mask_inv = (~padding_mask)\n",
    "\n",
    "input_encoding_dim = 512\n",
    "q=21\n",
    "param_embed_dim = 512\n",
    "n_param_heads = 4\n",
    "d_model = 128\n",
    "n_heads = 2\n",
    "n_layers = 2\n",
    "device = 0\n",
    "eta = 1e-3\n",
    "dropout = 0.0\n",
    "K = n_param_heads\n",
    "device=1\n",
    "\n",
    "decoder = PottsDecoder(q, n_layers, d_model, input_encoding_dim, param_embed_dim, n_heads, n_param_heads, dropout=dropout)\n",
    "\n",
    "#model_path = '/media/luchinoprince/b1715ef3-045d-4bdf-b216-c211472fb5a2/Data/InverseFolding/Intermediate_Models/model_04_01_2023.pt'\n",
    "#checkpoint = torch.load(model_path)\n",
    "\n",
    "q=21\n",
    "#args = checkpoint['args']\n",
    "decoder.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_embeddings, fields, logZ = decoder.forward(encodings, padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 6, 21])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nce import nce, loglik_potts, loglik_indep, sample_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = torch.rand(B, N, q)\n",
    "fi = fi / torch.sum(fi,axis=2).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ind = sample_ind(fi, n_samples=M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ind = torch.transpose(samples_ind, 0, 1)\n",
    "samples_ind_embedded = embeddings(samples_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20, 6, 21])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msas_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20, 6, 21])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_ind_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_full = torch.concat([msas_embedded, samples_ind_embedded], axis=1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 6, 21])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V = torch.randn((B, K, N, q))\n",
    "#fields = torch.randn((B, N, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logZ = torch.log(torch.rand((B, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lprobs: tensor([[[-2.5328, -2.6902, -3.2032, -3.6385, -2.8799, -2.5625],\n",
      "         [-2.9088, -2.4310, -5.4418, -2.4707, -4.4348, -2.4016],\n",
      "         [-3.2980, -5.5168, -2.3000, -2.5975, -2.5798, -2.7755],\n",
      "         [-2.3477, -5.5168, -2.7695, -2.3389, -5.0443, -2.4016],\n",
      "         [-2.4371, -2.3699, -4.8424, -3.1169, -3.1859, -2.3699],\n",
      "         [-2.4886, -4.0973, -2.4428, -6.8887, -2.8243, -3.2987],\n",
      "         [-3.9937, -2.7036, -3.4697, -2.2696, -2.9139, -5.0211],\n",
      "         [-3.2206, -2.6207, -5.0968, -2.5040, -3.2096, -4.5869],\n",
      "         [-3.3876, -2.4190, -5.0410, -4.5019, -2.9139, -2.4016],\n",
      "         [-4.6455, -2.4310, -2.5890, -2.4707, -2.9139, -5.0211],\n",
      "         [-2.4886, -2.7036, -3.5562, -2.5975, -2.6447, -3.2030],\n",
      "         [-6.0371, -3.2282, -2.5890, -2.4707, -2.6447, -2.7111],\n",
      "         [-4.6455, -2.4310, -5.0968, -2.9352, -4.0407, -3.2987],\n",
      "         [-2.3477, -4.0973, -3.5562, -2.3389, -2.6447, -3.5834],\n",
      "         [-2.7536, -4.3216, -4.8424, -2.8885, -3.3517, -4.5869],\n",
      "         [-2.7260, -5.5168, -3.4697, -4.0274, -2.5798, -3.2987],\n",
      "         [-3.3876, -2.6207, -2.5890, -2.8885, -2.8799, -5.0211],\n",
      "         [-2.3477, -2.5213, -2.3886, -3.1443, -2.9139, -2.7111],\n",
      "         [-3.6154, -2.3699, -2.8366, -2.5040, -3.0529, -2.7111],\n",
      "         [-2.4371, -5.5168, -3.5562, -2.5040, -3.8710, -2.9058],\n",
      "         [-2.4743, -2.6207, -3.4697, -2.9352, -2.5119, -2.8442],\n",
      "         [-3.6154, -2.8057, -2.5527, -2.9359, -2.8799, -2.3699],\n",
      "         [-2.5328, -2.6207, -2.4921, -2.9352, -2.9897, -2.3699],\n",
      "         [-3.7843, -2.7036, -2.4921, -2.5040, -2.5119, -4.5869],\n",
      "         [-2.3477, -2.5213, -3.0254, -2.9352, -3.3517, -3.8142],\n",
      "         [-2.5328, -2.8057, -2.5527, -3.4233, -2.6613, -2.4016],\n",
      "         [-2.4886, -2.5417, -2.8366, -3.1443, -2.6447, -2.3699],\n",
      "         [-3.2206, -3.0284, -2.3000, -2.2696, -2.6578, -2.3699],\n",
      "         [-2.9088, -2.4190, -2.5890, -4.0274, -3.0529, -2.4016],\n",
      "         [-3.2980, -3.8156, -3.5628, -2.5975, -2.5798, -2.7815],\n",
      "         [-2.4743, -2.4190, -2.5527, -2.8032, -2.8799, -3.2918],\n",
      "         [-2.3477, -2.5213, -2.3000, -2.2696, -2.9139, -2.9660],\n",
      "         [-2.7536, -2.4190, -2.3886, -2.9359, -2.8243, -2.7755],\n",
      "         [-2.7536, -4.6341, -2.3000, -3.9123, -2.5798, -2.3699],\n",
      "         [-3.2206, -2.7883, -3.4697, -2.3389, -2.6613, -3.2987],\n",
      "         [-3.2980, -2.7883, -2.8366, -2.9009, -3.2096, -2.7815],\n",
      "         [-2.7536, -4.3216, -3.2032, -2.5040, -2.6578, -2.9166],\n",
      "         [-2.9088, -3.8156, -2.3000, -2.8400, -4.0407, -2.9660],\n",
      "         [-2.7536, -2.5417, -3.2032, -2.5040, -2.6868, -2.7755],\n",
      "         [-2.4743, -2.8057, -2.5527, -2.4707, -2.6868, -2.9166]],\n",
      "\n",
      "        [[-6.1392, -2.3912, -2.8896, -3.7452, -3.5423, -3.2780],\n",
      "         [-2.6913, -3.6427, -2.5416, -2.4825, -3.5515, -3.0050],\n",
      "         [-2.3426, -2.3771, -2.6665, -2.7743, -4.1953, -3.0142],\n",
      "         [-3.3297, -2.3771, -2.6869, -4.2131, -4.1953, -4.1553],\n",
      "         [-3.2246, -3.6356, -2.7456, -7.8370, -2.7582, -2.4576],\n",
      "         [-3.3289, -3.6356, -2.5073, -3.8935, -2.4796, -3.1013],\n",
      "         [-3.0542, -3.3962, -4.1958, -3.9845, -2.7468, -3.2780],\n",
      "         [-2.6496, -2.2464, -2.7456, -3.0601, -2.7468, -2.3343],\n",
      "         [-2.8597, -2.3937, -2.4934, -3.1242, -2.9268, -4.5206],\n",
      "         [-2.5158, -2.5226, -2.6869, -2.8375, -2.9268, -2.9237],\n",
      "         [-2.3426, -4.7364, -3.8735, -2.8375, -4.3756, -2.4576],\n",
      "         [-2.6496, -3.6356, -3.8638, -3.8935, -2.4355, -3.2703],\n",
      "         [-6.7156, -3.3962, -2.7542, -3.9845, -3.5423, -3.0142],\n",
      "         [-2.6209, -2.5226, -5.0569, -2.8375, -6.5801, -2.9804],\n",
      "         [-3.0684, -3.3962, -2.7600, -3.9845, -3.5423, -4.5206],\n",
      "         [-3.0684, -3.3962, -2.5073, -3.9845, -2.9268, -3.0142],\n",
      "         [-2.6496, -7.5985, -2.6869, -3.8935, -2.7582, -3.0068],\n",
      "         [-2.8235, -3.3962, -3.4669, -3.8116, -2.4355, -4.5206],\n",
      "         [-2.6496, -2.6183, -2.6869, -3.0601, -2.5123, -5.2626],\n",
      "         [-3.3297, -3.0960, -2.6665, -2.7743, -3.5423, -4.1978],\n",
      "         [-2.6209, -2.3771, -2.7600, -3.1418, -2.7468, -3.0068],\n",
      "         [-2.3426, -2.5226, -2.7600, -3.1385, -2.7582, -2.3371],\n",
      "         [-2.5158, -3.6356, -3.4123, -3.9845, -2.4355, -2.9237],\n",
      "         [-2.6496, -2.3912, -2.8882, -4.2010, -2.5123, -3.2780],\n",
      "         [-2.6913, -3.3867, -2.4934, -3.8935, -2.8306, -3.0050],\n",
      "         [-2.6496, -2.8660, -2.5416, -2.4514, -2.4796, -2.9340],\n",
      "         [-3.2246, -2.6183, -2.6665, -2.3719, -2.6551, -2.9804],\n",
      "         [-3.0112, -4.1316, -2.4934, -3.8116, -2.8306, -3.1013],\n",
      "         [-3.3297, -2.3912, -2.8882, -4.2010, -2.3807, -2.3343],\n",
      "         [-2.6496, -2.7363, -2.6665, -2.4825, -3.5423, -2.3343],\n",
      "         [-4.9223, -2.3912, -2.6869, -2.7259, -2.6551, -2.3343],\n",
      "         [-3.0967, -2.2464, -2.6665, -2.5504, -2.7582, -2.4576],\n",
      "         [-2.6913, -2.3771, -2.8882, -2.4825, -2.4355, -3.2780],\n",
      "         [-2.3533, -2.3912, -2.5722, -2.4514, -2.8696, -4.1523],\n",
      "         [-2.5158, -2.8660, -2.7542, -3.8935, -2.3807, -2.5879],\n",
      "         [-3.0112, -2.5226, -2.8896, -3.1418, -2.7468, -2.3343],\n",
      "         [-2.5158, -2.3937, -2.5722, -2.4514, -2.8306, -2.4576],\n",
      "         [-2.8235, -2.3771, -2.5388, -2.7743, -2.9168, -2.9340],\n",
      "         [-2.8235, -3.6356, -2.5416, -2.4465, -2.4796, -2.3343],\n",
      "         [-2.6209, -2.6751, -2.6665, -2.3719, -2.8306, -2.5879]],\n",
      "\n",
      "        [[-2.5856, -2.7291, -2.7157, -2.8750, -2.4373, -2.6053],\n",
      "         [-2.7556, -4.5265, -3.3137, -2.8750, -3.2599, -5.5330],\n",
      "         [-2.7915, -2.4060, -3.4513, -4.0436, -5.2732, -2.9121],\n",
      "         [-3.6366, -2.7291, -3.1168, -2.6327, -2.3259, -2.6097],\n",
      "         [-3.9050, -2.7026, -2.7157, -2.6327, -3.2599, -5.5330],\n",
      "         [-2.5985, -4.7851, -3.4652, -5.5693, -2.9096, -3.0211],\n",
      "         [-4.0506, -5.5389, -3.4652, -2.9033, -2.9159, -5.5330],\n",
      "         [-2.7556, -2.4527, -2.5510, -4.8320, -3.2599, -2.9121],\n",
      "         [-2.7556, -6.5981, -3.4513, -2.5989, -2.3259, -5.5330],\n",
      "         [-3.2453, -2.4060, -5.9799, -5.5693, -4.1010, -3.1411],\n",
      "         [-2.6838, -6.5981, -5.9799, -5.5693, -3.2599, -2.8822],\n",
      "         [-3.2453, -2.4799, -3.2759, -4.8320, -3.2599, -4.6464],\n",
      "         [-2.7915, -2.5373, -3.4513, -2.4666, -2.4895, -4.9113],\n",
      "         [-2.7915, -2.4799, -2.5510, -2.9339, -2.7510, -5.5330],\n",
      "         [-3.9964, -6.5981, -3.1168, -3.4114, -2.8664, -2.5744],\n",
      "         [-3.2453, -2.4527, -2.7754, -2.8630, -3.7230, -5.3715],\n",
      "         [-3.2453, -2.4799, -3.2759, -2.8750, -3.2125, -2.2370],\n",
      "         [-3.0941, -3.0128, -3.3137, -2.6730, -2.4373, -2.3434],\n",
      "         [-3.2453, -2.7026, -3.3599, -5.5693, -2.4568, -5.3715],\n",
      "         [-3.0017, -6.4554, -2.9535, -2.5127, -2.4895, -3.0211],\n",
      "         [-2.5856, -2.5563, -2.5510, -2.4803, -2.4895, -2.6097],\n",
      "         [-2.5856, -2.4070, -3.4028, -2.8630, -2.4895, -2.4219],\n",
      "         [-2.6838, -2.4527, -2.7157, -2.8411, -2.4895, -2.4219],\n",
      "         [-3.0017, -2.4799, -2.7320, -2.8411, -2.4568, -2.9121],\n",
      "         [-2.7348, -4.7851, -2.7754, -2.6327, -4.1771, -2.9121],\n",
      "         [-2.6073, -2.4799, -2.7648, -2.4803, -3.6418, -2.4219],\n",
      "         [-3.2453, -2.7291, -3.2759, -2.8750, -2.9159, -2.4219],\n",
      "         [-2.6838, -2.4070, -2.5510, -2.5127, -2.3098, -2.3434],\n",
      "         [-2.7624, -2.5563, -3.1168, -2.8720, -3.6418, -3.1411],\n",
      "         [-2.6073, -3.0128, -2.7320, -2.6327, -3.7230, -2.6097],\n",
      "         [-2.6111, -2.5563, -2.5929, -3.4114, -2.4373, -2.6097],\n",
      "         [-3.9050, -2.5373, -3.1168, -2.5127, -2.9159, -3.0211],\n",
      "         [-2.7915, -2.4060, -2.7320, -4.3088, -2.3098, -3.3037],\n",
      "         [-3.6915, -2.5373, -2.7157, -2.6730, -3.2125, -2.4219],\n",
      "         [-2.6073, -3.5633, -3.4028, -2.8720, -2.3259, -2.6097],\n",
      "         [-3.6366, -2.4060, -3.4028, -2.8720, -2.6272, -2.5744],\n",
      "         [-3.0941, -3.0128, -3.3137, -2.8720, -2.3259, -3.3037],\n",
      "         [-2.7348, -2.7026, -3.3137, -5.5693, -2.3259, -2.8822],\n",
      "         [-2.6111, -2.5563, -2.7754, -2.4803, -2.4568, -2.2370],\n",
      "         [-2.6111, -2.5563, -3.3044, -2.8750, -2.3098, -2.4219]]])\n",
      "Fi:  tensor([[[0.0227, 0.0545, 0.0338, 0.0399, 0.0184, 0.0794, 0.0370, 0.0111,\n",
      "          0.0078, 0.0096, 0.0874, 0.0269, 0.0718, 0.0637, 0.0956, 0.0935,\n",
      "          0.0842, 0.0655, 0.0024, 0.0830, 0.0117],\n",
      "         [0.0679, 0.0615, 0.0097, 0.0670, 0.0804, 0.0879, 0.0040, 0.0219,\n",
      "          0.0326, 0.0396, 0.0935, 0.0166, 0.0890, 0.0133, 0.0132, 0.0787,\n",
      "          0.0220, 0.0605, 0.0727, 0.0195, 0.0484],\n",
      "         [0.0586, 0.0065, 0.0869, 0.0064, 0.1003, 0.0751, 0.0311, 0.0079,\n",
      "          0.0519, 0.0406, 0.0918, 0.0827, 0.0779, 0.0385, 0.0627, 0.0285,\n",
      "          0.0043, 0.0485, 0.0061, 0.0284, 0.0652],\n",
      "         [0.0531, 0.0200, 0.0010, 0.1034, 0.0584, 0.0015, 0.0111, 0.0178,\n",
      "          0.0964, 0.0818, 0.0550, 0.0745, 0.0845, 0.0531, 0.0557, 0.0606,\n",
      "          0.0259, 0.0326, 0.0263, 0.0431, 0.0443],\n",
      "         [0.0350, 0.0208, 0.0710, 0.0637, 0.0176, 0.0758, 0.0472, 0.0064,\n",
      "          0.0332, 0.0503, 0.0811, 0.0681, 0.0413, 0.0561, 0.0404, 0.0263,\n",
      "          0.0119, 0.0701, 0.0699, 0.0543, 0.0594],\n",
      "         [0.0372, 0.0547, 0.0277, 0.0619, 0.0906, 0.0582, 0.0369, 0.0278,\n",
      "          0.0532, 0.0515, 0.0541, 0.0066, 0.0665, 0.0221, 0.0542, 0.0935,\n",
      "          0.0131, 0.0102, 0.0623, 0.0771, 0.0406]],\n",
      "\n",
      "        [[0.0022, 0.0472, 0.0372, 0.0678, 0.0707, 0.0398, 0.0951, 0.0961,\n",
      "          0.0594, 0.0452, 0.0358, 0.0573, 0.0727, 0.0334, 0.0492, 0.0194,\n",
      "          0.0808, 0.0465, 0.0073, 0.0358, 0.0012],\n",
      "         [0.0729, 0.0262, 0.0264, 0.1058, 0.0202, 0.0689, 0.0338, 0.0913,\n",
      "          0.0161, 0.0088, 0.0452, 0.0803, 0.0569, 0.0928, 0.0335, 0.0005,\n",
      "          0.0215, 0.0915, 0.0351, 0.0076, 0.0648],\n",
      "         [0.0064, 0.0815, 0.0637, 0.0151, 0.0258, 0.0031, 0.0312, 0.0208,\n",
      "          0.0557, 0.0633, 0.0056, 0.0330, 0.0764, 0.0642, 0.0787, 0.0556,\n",
      "          0.0695, 0.0210, 0.0681, 0.0790, 0.0826],\n",
      "         [0.0148, 0.0236, 0.0933, 0.0866, 0.0204, 0.0835, 0.0186, 0.0150,\n",
      "          0.0004, 0.0433, 0.0862, 0.0221, 0.0624, 0.0440, 0.0432, 0.0586,\n",
      "          0.0780, 0.0655, 0.0928, 0.0007, 0.0469],\n",
      "         [0.0289, 0.0014, 0.0151, 0.0811, 0.0634, 0.0641, 0.0049, 0.0450,\n",
      "          0.0519, 0.0126, 0.0590, 0.0127, 0.0703, 0.0838, 0.0541, 0.0327,\n",
      "          0.0536, 0.0925, 0.0876, 0.0287, 0.0567],\n",
      "         [0.0450, 0.0966, 0.0380, 0.0157, 0.0537, 0.0109, 0.0157, 0.0377,\n",
      "          0.0052, 0.0752, 0.0532, 0.0856, 0.0491, 0.0640, 0.0495, 0.0806,\n",
      "          0.0150, 0.0495, 0.0508, 0.0121, 0.0969]],\n",
      "\n",
      "        [[0.0683, 0.0636, 0.0481, 0.0174, 0.0744, 0.0436, 0.0497, 0.0613,\n",
      "          0.0249, 0.0068, 0.0184, 0.0390, 0.0453, 0.0754, 0.0737, 0.0631,\n",
      "          0.0421, 0.0263, 0.0201, 0.0735, 0.0649],\n",
      "         [0.0039, 0.0861, 0.0670, 0.0360, 0.0492, 0.0014, 0.0471, 0.0310,\n",
      "          0.0263, 0.0902, 0.0341, 0.0901, 0.0283, 0.0791, 0.0016, 0.0776,\n",
      "          0.0653, 0.0837, 0.0830, 0.0084, 0.0108],\n",
      "         [0.0333, 0.0748, 0.0025, 0.0297, 0.0347, 0.0662, 0.0313, 0.0364,\n",
      "          0.0367, 0.0780, 0.0596, 0.0630, 0.0651, 0.0317, 0.0577, 0.0522,\n",
      "          0.0615, 0.0378, 0.0443, 0.0412, 0.0623],\n",
      "         [0.0175, 0.0744, 0.0837, 0.0566, 0.0038, 0.0548, 0.0435, 0.0584,\n",
      "          0.0134, 0.0080, 0.0159, 0.0564, 0.0849, 0.0571, 0.0690, 0.0148,\n",
      "          0.0330, 0.0810, 0.0486, 0.0719, 0.0532],\n",
      "         [0.0158, 0.0857, 0.0153, 0.0977, 0.0242, 0.0830, 0.0384, 0.0166,\n",
      "          0.0639, 0.0023, 0.0569, 0.0542, 0.0874, 0.0545, 0.0723, 0.0051,\n",
      "          0.0993, 0.0403, 0.0262, 0.0572, 0.0039],\n",
      "         [0.0155, 0.0081, 0.0887, 0.0074, 0.0367, 0.0762, 0.0143, 0.0046,\n",
      "          0.0560, 0.0544, 0.0960, 0.0487, 0.0739, 0.0166, 0.1068, 0.0896,\n",
      "          0.0736, 0.0762, 0.0432, 0.0096, 0.0040]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-16.4685)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.min(loglik_indep(fi, samples_full, padding_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 6, 21])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 21])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_mask_inv = (~padding_mask)\n",
    "## (B, n_param_heads, N, q) * (B, 1, N, 1) = (B, K, N, q)\n",
    "# set embeddings to zero where padding is present\n",
    "param_embeddings2 = V * padding_mask_inv.unsqueeze(1).unsqueeze(3) \n",
    "\n",
    "fields2 = fields * padding_mask_inv.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=fields2\n",
    "V=param_embeddings2\n",
    "K = V.shape[1]\n",
    "B, M, _, _ = msas_embedded.shape\n",
    "\n",
    "## (B, 1, K, M, q) * (B, M, 1, N, q) = (B, M, K, N, q)  ---> (B, M, K, N)\n",
    "V_data = torch.sum(torch.unsqueeze(V, dim=1) * \n",
    "                    torch.unsqueeze(msas_embedded, dim=2), axis=-1)\n",
    "\n",
    "## (B, M, K, N)  ---> (B, M, K)\n",
    "S_k = torch.sum(V_data, axis=-1)\n",
    "H_k = torch.sum(V_data**2, axis=-1)\n",
    "\n",
    "## (B, M, K)  ---> (B, M)\n",
    "E = torch.sum(S_k**2 - H_k, axis=-1)\n",
    "\n",
    "## (B, 1, N, q) * (B, M, N, q) = (B, M, N, q) ---> (B, M, N)\n",
    "Fi_data = torch.sum(torch.unsqueeze(F, dim=1) * msas_embedded, axis=-1)\n",
    "\n",
    "## Fs is the field component of the sequence s: (B, M, N) --> (B, M) \n",
    "Fs = torch.sum(Fi_data, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6, 21])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 20, 6)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, M, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 6, 21])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprobs_i = torch.log(torch.sum(torch.unsqueeze(fi, dim=1) * samples_full, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 6])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lprobs_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lprobs_i = lprobs_i * padding_mask_inv.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.7959, -2.8887, -0.0000, -3.2665, -3.2788, -0.0000],\n",
       "         [-2.7959, -2.4124, -0.0000, -2.7914, -2.9853, -0.0000],\n",
       "         [-4.1576, -2.9103, -0.0000, -3.3538, -2.7442, -0.0000],\n",
       "         [-3.1487, -2.4124, -0.0000, -2.5161, -3.3445, -0.0000],\n",
       "         [-2.7556, -5.0797, -0.0000, -4.6907, -2.7565, -0.0000],\n",
       "         [-2.7959, -2.3490, -0.0000, -3.1399, -3.2788, -0.0000],\n",
       "         [-3.5369, -2.3025, -0.0000, -4.6907, -3.8780, -0.0000],\n",
       "         [-3.1141, -2.6681, -0.0000, -4.5578, -3.0445, -0.0000],\n",
       "         [-2.4845, -2.3490, -0.0000, -2.6056, -3.2024, -0.0000],\n",
       "         [-3.1164, -4.5041, -0.0000, -2.5763, -3.3445, -0.0000],\n",
       "         [-2.3043, -4.4000, -0.0000, -2.5675, -2.8260, -0.0000],\n",
       "         [-2.3352, -3.8065, -0.0000, -3.1399, -2.8260, -0.0000],\n",
       "         [-2.3043, -2.5659, -0.0000, -4.4705, -2.7431, -0.0000],\n",
       "         [-2.3622, -2.5433, -0.0000, -4.6907, -2.7106, -0.0000],\n",
       "         [-2.3622, -2.6681, -0.0000, -2.4051, -3.9773, -0.0000],\n",
       "         [-3.1141, -2.9139, -0.0000, -2.5161, -3.8780, -0.0000],\n",
       "         [-2.6612, -2.8887, -0.0000, -4.5578, -3.2788, -0.0000],\n",
       "         [-2.3043, -4.4000, -0.0000, -3.1399, -2.8260, -0.0000],\n",
       "         [-2.6612, -2.9139, -0.0000, -4.5578, -3.2024, -0.0000],\n",
       "         [-3.4256, -3.3644, -0.0000, -2.7914, -3.0445, -0.0000],\n",
       "         [-3.4847, -2.9139, -0.0000, -2.5161, -3.1248, -0.0000],\n",
       "         [-2.3352, -4.5442, -0.0000, -3.1051, -3.0445, -0.0000],\n",
       "         [-2.4845, -2.6103, -0.0000, -2.5675, -2.7565, -0.0000],\n",
       "         [-3.1727, -2.3025, -0.0000, -2.5675, -3.2024, -0.0000],\n",
       "         [-2.4845, -2.4124, -0.0000, -2.4051, -2.8260, -0.0000],\n",
       "         [-2.7556, -2.3490, -0.0000, -2.6134, -3.1248, -0.0000],\n",
       "         [-2.6581, -2.5570, -0.0000, -3.1736, -3.9773, -0.0000],\n",
       "         [-3.1727, -2.4124, -0.0000, -2.6134, -3.9773, -0.0000],\n",
       "         [-3.1487, -2.6681, -0.0000, -2.7914, -3.8780, -0.0000],\n",
       "         [-2.4845, -3.3644, -0.0000, -2.7914, -3.2024, -0.0000],\n",
       "         [-2.3352, -2.3025, -0.0000, -2.6056, -3.8097, -0.0000],\n",
       "         [-2.3352, -2.3490, -0.0000, -3.2665, -2.8260, -0.0000],\n",
       "         [-2.3043, -2.5659, -0.0000, -2.5763, -2.6949, -0.0000],\n",
       "         [-2.3352, -2.6681, -0.0000, -3.3538, -3.2024, -0.0000],\n",
       "         [-3.1164, -2.6103, -0.0000, -2.7914, -2.7442, -0.0000],\n",
       "         [-2.7556, -2.6103, -0.0000, -3.2665, -2.7431, -0.0000],\n",
       "         [-3.1235, -2.5659, -0.0000, -3.1051, -3.9773, -0.0000],\n",
       "         [-4.1576, -2.3025, -0.0000, -2.6056, -2.7106, -0.0000],\n",
       "         [-3.1235, -2.9103, -0.0000, -3.4602, -2.7442, -0.0000],\n",
       "         [-2.3043, -2.6681, -0.0000, -2.5161, -2.6008, -0.0000]],\n",
       "\n",
       "        [[-0.0000, -0.0000, -3.5341, -2.9509, -5.2166, -3.9721],\n",
       "         [-0.0000, -0.0000, -3.3361, -3.4571, -2.5244, -2.6216],\n",
       "         [-0.0000, -0.0000, -3.0820, -2.9509, -2.8076, -2.7373],\n",
       "         [-0.0000, -0.0000, -2.5714, -2.4005, -6.0187, -3.8890],\n",
       "         [-0.0000, -0.0000, -2.4104, -4.5430, -3.9507, -3.9121],\n",
       "         [-0.0000, -0.0000, -2.8631, -2.9509, -3.3546, -3.0308],\n",
       "         [-0.0000, -0.0000, -2.4322, -3.7688, -3.1681, -2.8722],\n",
       "         [-0.0000, -0.0000, -2.4104, -3.4571, -2.6845, -2.6216],\n",
       "         [-0.0000, -0.0000, -3.2720, -3.3940, -2.7427, -2.8914],\n",
       "         [-0.0000, -0.0000, -5.5642, -3.7688, -3.4962, -2.5728],\n",
       "         [-0.0000, -0.0000, -3.3891, -3.3940, -2.3338, -2.8722],\n",
       "         [-0.0000, -0.0000, -2.8381, -2.4005, -3.8706, -3.0760],\n",
       "         [-0.0000, -0.0000, -3.2720, -3.3940, -4.2979, -3.0369],\n",
       "         [-0.0000, -0.0000, -2.6191, -4.2404, -2.3338, -3.6410],\n",
       "         [-0.0000, -0.0000, -3.3361, -4.5430, -2.5080, -3.2699],\n",
       "         [-0.0000, -0.0000, -3.0687, -6.2611, -2.9966, -3.0760],\n",
       "         [-0.0000, -0.0000, -3.5341, -2.9509, -3.1681, -2.8722],\n",
       "         [-0.0000, -0.0000, -3.5341, -2.4271, -3.3546, -2.8914],\n",
       "         [-0.0000, -0.0000, -2.4322, -6.2611, -3.9507, -2.6942],\n",
       "         [-0.0000, -0.0000, -2.8901, -2.6902, -2.8929, -2.5728],\n",
       "         [-0.0000, -0.0000, -2.4322, -2.4276, -2.8929, -2.6942],\n",
       "         [-0.0000, -0.0000, -2.5714, -2.4271, -3.9507, -2.5728],\n",
       "         [-0.0000, -0.0000, -3.2720, -3.3940, -2.5080, -2.8914],\n",
       "         [-0.0000, -0.0000, -2.5714, -2.9680, -3.3546, -2.5728],\n",
       "         [-0.0000, -0.0000, -3.2354, -2.4005, -2.3842, -3.8890],\n",
       "         [-0.0000, -0.0000, -3.3891, -2.2838, -3.4962, -3.0766],\n",
       "         [-0.0000, -0.0000, -3.2354, -2.5676, -2.7336, -2.8722],\n",
       "         [-0.0000, -0.0000, -3.0820, -4.2404, -2.3842, -3.8890],\n",
       "         [-0.0000, -0.0000, -3.5341, -2.8989, -2.8076, -2.6942],\n",
       "         [-0.0000, -0.0000, -2.4322, -4.2404, -2.9966, -2.4098],\n",
       "         [-0.0000, -0.0000, -3.0820, -2.4271, -2.7336, -2.8914],\n",
       "         [-0.0000, -0.0000, -2.8381, -2.4005, -2.3338, -2.8722],\n",
       "         [-0.0000, -0.0000, -2.5714, -2.4271, -3.3546, -2.5559],\n",
       "         [-0.0000, -0.0000, -3.3361, -2.5676, -3.7405, -3.2699],\n",
       "         [-0.0000, -0.0000, -2.6191, -4.5430, -2.3842, -2.8914],\n",
       "         [-0.0000, -0.0000, -3.0687, -3.3940, -2.3338, -3.0308],\n",
       "         [-0.0000, -0.0000, -2.8631, -2.5676, -2.3842, -3.0766],\n",
       "         [-0.0000, -0.0000, -2.4237, -2.4271, -2.9966, -3.6410],\n",
       "         [-0.0000, -0.0000, -2.6191, -2.4005, -3.4962, -2.4098],\n",
       "         [-0.0000, -0.0000, -2.9162, -3.0832, -2.7336, -2.8914]],\n",
       "\n",
       "        [[-4.3211, -0.0000, -4.0934, -2.8143, -0.0000, -0.0000],\n",
       "         [-2.8375, -0.0000, -2.8242, -2.7304, -0.0000, -0.0000],\n",
       "         [-5.2617, -0.0000, -2.9328, -4.3643, -0.0000, -0.0000],\n",
       "         [-5.2617, -0.0000, -4.3570, -2.7194, -0.0000, -0.0000],\n",
       "         [-2.7690, -0.0000, -2.6709, -4.4428, -0.0000, -0.0000],\n",
       "         [-2.9699, -0.0000, -3.0892, -2.5122, -0.0000, -0.0000],\n",
       "         [-2.7690, -0.0000, -2.8842, -2.7194, -0.0000, -0.0000],\n",
       "         [-2.8025, -0.0000, -2.3895, -2.7194, -0.0000, -0.0000],\n",
       "         [-4.3211, -0.0000, -3.0892, -3.5432, -0.0000, -0.0000],\n",
       "         [-3.6535, -0.0000, -3.3332, -4.1445, -0.0000, -0.0000],\n",
       "         [-2.6821, -0.0000, -4.0934, -3.5432, -0.0000, -0.0000],\n",
       "         [-2.6314, -0.0000, -2.7128, -2.7242, -0.0000, -0.0000],\n",
       "         [-2.7043, -0.0000, -2.7128, -4.1445, -0.0000, -0.0000],\n",
       "         [-2.7043, -0.0000, -3.0162, -2.9864, -0.0000, -0.0000],\n",
       "         [-2.3845, -0.0000, -3.3332, -2.6475, -0.0000, -0.0000],\n",
       "         [-2.4033, -0.0000, -3.2589, -3.3335, -0.0000, -0.0000],\n",
       "         [-3.6535, -0.0000, -2.5804, -4.3643, -0.0000, -0.0000],\n",
       "         [-2.7238, -0.0000, -2.8242, -4.1445, -0.0000, -0.0000],\n",
       "         [-3.6535, -0.0000, -3.2589, -2.7304, -0.0000, -0.0000],\n",
       "         [-2.4033, -0.0000, -3.0892, -3.3725, -0.0000, -0.0000],\n",
       "         [-2.6821, -0.0000, -2.8242, -2.9740, -0.0000, -0.0000],\n",
       "         [-2.7690, -0.0000, -3.0112, -2.5122, -0.0000, -0.0000],\n",
       "         [-2.6005, -0.0000, -3.8479, -2.9864, -0.0000, -0.0000],\n",
       "         [-4.3582, -0.0000, -3.2589, -2.5498, -0.0000, -0.0000],\n",
       "         [-2.7238, -0.0000, -2.3895, -2.7242, -0.0000, -0.0000],\n",
       "         [-2.6005, -0.0000, -2.7128, -2.7194, -0.0000, -0.0000],\n",
       "         [-4.5369, -0.0000, -2.8242, -2.5951, -0.0000, -0.0000],\n",
       "         [-2.8025, -0.0000, -2.7128, -3.3725, -0.0000, -0.0000],\n",
       "         [-2.4033, -0.0000, -2.9328, -3.0471, -0.0000, -0.0000],\n",
       "         [-2.7449, -0.0000, -2.4252, -2.9864, -0.0000, -0.0000],\n",
       "         [-2.4033, -0.0000, -2.3895, -3.3725, -0.0000, -0.0000],\n",
       "         [-2.6314, -0.0000, -2.7128, -2.7304, -0.0000, -0.0000],\n",
       "         [-2.6005, -0.0000, -2.6709, -2.9740, -0.0000, -0.0000],\n",
       "         [-2.3845, -0.0000, -4.3570, -3.5432, -0.0000, -0.0000],\n",
       "         [-2.3845, -0.0000, -2.3895, -2.5498, -0.0000, -0.0000],\n",
       "         [-2.6314, -0.0000, -3.3447, -3.0421, -0.0000, -0.0000],\n",
       "         [-3.9243, -0.0000, -2.9328, -2.6475, -0.0000, -0.0000],\n",
       "         [-2.7690, -0.0000, -2.8842, -3.7399, -0.0000, -0.0000],\n",
       "         [-2.7690, -0.0000, -3.8479, -2.5951, -0.0000, -0.0000],\n",
       "         [-2.6314, -0.0000, -2.8842, -2.7242, -0.0000, -0.0000]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lprobs_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_mask = fi * padding_mask.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_i = torch.sum(torch.unsqueeze(fi_mask, dim=1) * samples_full, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0569, 0.0050, 0.0000, 0.0299, 0.0982, 0.0000],\n",
       "         [0.0569, 0.0645, 0.0000, 0.0503, 0.0048, 0.0000],\n",
       "         [0.0531, 0.0403, 0.0000, 0.0983, 0.0003, 0.0000],\n",
       "         [0.0109, 0.0645, 0.0000, 0.0180, 0.0225, 0.0000],\n",
       "         [0.0815, 0.0557, 0.0000, 0.0749, 0.0655, 0.0000],\n",
       "         [0.0569, 0.0844, 0.0000, 0.0339, 0.0982, 0.0000],\n",
       "         [0.0218, 0.0212, 0.0000, 0.0749, 0.0504, 0.0000],\n",
       "         [0.0459, 0.0189, 0.0000, 0.0408, 0.0469, 0.0000],\n",
       "         [0.0037, 0.0844, 0.0000, 0.0248, 0.0068, 0.0000],\n",
       "         [0.0811, 0.0049, 0.0000, 0.0045, 0.0225, 0.0000],\n",
       "         [0.0594, 0.0013, 0.0000, 0.0264, 0.0965, 0.0000],\n",
       "         [0.0893, 0.0512, 0.0000, 0.0339, 0.0965, 0.0000],\n",
       "         [0.0594, 0.0264, 0.0000, 0.0128, 0.0258, 0.0000],\n",
       "         [0.0002, 0.0184, 0.0000, 0.0749, 0.0836, 0.0000],\n",
       "         [0.0002, 0.0189, 0.0000, 0.0679, 0.0435, 0.0000],\n",
       "         [0.0459, 0.0471, 0.0000, 0.0180, 0.0504, 0.0000],\n",
       "         [0.0510, 0.0050, 0.0000, 0.0408, 0.0982, 0.0000],\n",
       "         [0.0594, 0.0013, 0.0000, 0.0339, 0.0965, 0.0000],\n",
       "         [0.0510, 0.0471, 0.0000, 0.0408, 0.0068, 0.0000],\n",
       "         [0.0525, 0.0491, 0.0000, 0.0503, 0.0469, 0.0000],\n",
       "         [0.0531, 0.0844, 0.0000, 0.0905, 0.0353, 0.0000],\n",
       "         [0.0531, 0.0512, 0.0000, 0.0883, 0.0504, 0.0000],\n",
       "         [0.0569, 0.0926, 0.0000, 0.0749, 0.0929, 0.0000],\n",
       "         [0.0815, 0.0926, 0.0000, 0.0408, 0.0929, 0.0000],\n",
       "         [0.0815, 0.0512, 0.0000, 0.0883, 0.0504, 0.0000],\n",
       "         [0.0594, 0.0251, 0.0000, 0.0264, 0.0929, 0.0000],\n",
       "         [0.0218, 0.1112, 0.0000, 0.0408, 0.0577, 0.0000],\n",
       "         [0.0664, 0.0557, 0.0000, 0.0679, 0.0929, 0.0000],\n",
       "         [0.0532, 0.0926, 0.0000, 0.0679, 0.0982, 0.0000],\n",
       "         [0.0860, 0.0472, 0.0000, 0.0045, 0.0724, 0.0000],\n",
       "         [0.0811, 0.1112, 0.0000, 0.0983, 0.0655, 0.0000],\n",
       "         [0.0569, 0.0645, 0.0000, 0.0983, 0.0469, 0.0000],\n",
       "         [0.0594, 0.0482, 0.0000, 0.0555, 0.0749, 0.0000],\n",
       "         [0.0459, 0.0471, 0.0000, 0.0983, 0.0929, 0.0000],\n",
       "         [0.0569, 0.1070, 0.0000, 0.0983, 0.0655, 0.0000],\n",
       "         [0.0594, 0.0844, 0.0000, 0.0248, 0.0724, 0.0000],\n",
       "         [0.0859, 0.0471, 0.0000, 0.0905, 0.0749, 0.0000],\n",
       "         [0.0322, 0.1070, 0.0000, 0.0339, 0.0577, 0.0000],\n",
       "         [0.0218, 0.0844, 0.0000, 0.0806, 0.0655, 0.0000],\n",
       "         [0.0218, 0.0472, 0.0000, 0.0679, 0.0749, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000, 0.0750, 0.0130, 0.0277, 0.0143],\n",
       "         [0.0000, 0.0000, 0.0480, 0.0049, 0.0048, 0.0064],\n",
       "         [0.0000, 0.0000, 0.0200, 0.0130, 0.0295, 0.0119],\n",
       "         [0.0000, 0.0000, 0.0574, 0.0305, 0.0170, 0.0307],\n",
       "         [0.0000, 0.0000, 0.0030, 0.0739, 0.0016, 0.0804],\n",
       "         [0.0000, 0.0000, 0.0217, 0.0130, 0.0523, 0.0256],\n",
       "         [0.0000, 0.0000, 0.0146, 0.0610, 0.0904, 0.0882],\n",
       "         [0.0000, 0.0000, 0.0030, 0.0049, 0.0570, 0.0064],\n",
       "         [0.0000, 0.0000, 0.0805, 0.0790, 0.0727, 0.0788],\n",
       "         [0.0000, 0.0000, 0.0853, 0.0610, 0.1080, 0.0455],\n",
       "         [0.0000, 0.0000, 0.0090, 0.0790, 0.0646, 0.0882],\n",
       "         [0.0000, 0.0000, 0.0379, 0.0305, 0.0558, 0.0531],\n",
       "         [0.0000, 0.0000, 0.0805, 0.0790, 0.0162, 0.0436],\n",
       "         [0.0000, 0.0000, 0.0116, 0.0163, 0.0646, 0.0410],\n",
       "         [0.0000, 0.0000, 0.0480, 0.0739, 0.0305, 0.0340],\n",
       "         [0.0000, 0.0000, 0.0848, 0.0890, 0.0851, 0.0531],\n",
       "         [0.0000, 0.0000, 0.0750, 0.0130, 0.0904, 0.0882],\n",
       "         [0.0000, 0.0000, 0.0750, 0.0170, 0.0523, 0.0788],\n",
       "         [0.0000, 0.0000, 0.0146, 0.0890, 0.0016, 0.0621],\n",
       "         [0.0000, 0.0000, 0.0217, 0.0898, 0.0631, 0.0455],\n",
       "         [0.0000, 0.0000, 0.0809, 0.0411, 0.0851, 0.0882],\n",
       "         [0.0000, 0.0000, 0.0848, 0.0916, 0.0631, 0.0804],\n",
       "         [0.0000, 0.0000, 0.0805, 0.0916, 0.0295, 0.0621],\n",
       "         [0.0000, 0.0000, 0.0899, 0.0170, 0.0396, 0.0621],\n",
       "         [0.0000, 0.0000, 0.0853, 0.0411, 0.0305, 0.0804],\n",
       "         [0.0000, 0.0000, 0.0853, 0.0739, 0.0523, 0.0882],\n",
       "         [0.0000, 0.0000, 0.0848, 0.0739, 0.0851, 0.0804],\n",
       "         [0.0000, 0.0000, 0.0931, 0.0790, 0.0378, 0.0920],\n",
       "         [0.0000, 0.0000, 0.0848, 0.0788, 0.0114, 0.0307],\n",
       "         [0.0000, 0.0000, 0.0853, 0.0564, 0.0851, 0.0882],\n",
       "         [0.0000, 0.0000, 0.0480, 0.0936, 0.0851, 0.0621],\n",
       "         [0.0000, 0.0000, 0.1005, 0.0788, 0.0646, 0.0788],\n",
       "         [0.0000, 0.0000, 0.0480, 0.0739, 0.0727, 0.0064],\n",
       "         [0.0000, 0.0000, 0.0848, 0.0163, 0.0904, 0.0882],\n",
       "         [0.0000, 0.0000, 0.0480, 0.0936, 0.0646, 0.0621],\n",
       "         [0.0000, 0.0000, 0.0853, 0.0411, 0.0295, 0.0804],\n",
       "         [0.0000, 0.0000, 0.0805, 0.0110, 0.0570, 0.0621],\n",
       "         [0.0000, 0.0000, 0.1005, 0.0890, 0.0570, 0.0920],\n",
       "         [0.0000, 0.0000, 0.0217, 0.0610, 0.0378, 0.0882],\n",
       "         [0.0000, 0.0000, 0.0146, 0.0790, 0.0570, 0.0383]],\n",
       "\n",
       "        [[0.0156, 0.0000, 0.0157, 0.0450, 0.0000, 0.0000],\n",
       "         [0.0630, 0.0000, 0.0080, 0.0034, 0.0000, 0.0000],\n",
       "         [0.0589, 0.0000, 0.0384, 0.0202, 0.0000, 0.0000],\n",
       "         [0.0589, 0.0000, 0.0583, 0.0254, 0.0000, 0.0000],\n",
       "         [0.0563, 0.0000, 0.0210, 0.0250, 0.0000, 0.0000],\n",
       "         [0.0950, 0.0000, 0.0844, 0.0104, 0.0000, 0.0000],\n",
       "         [0.0563, 0.0000, 0.0075, 0.0254, 0.0000, 0.0000],\n",
       "         [0.0012, 0.0000, 0.0455, 0.0254, 0.0000, 0.0000],\n",
       "         [0.0156, 0.0000, 0.0844, 0.0526, 0.0000, 0.0000],\n",
       "         [0.0432, 0.0000, 0.0152, 0.0747, 0.0000, 0.0000],\n",
       "         [0.1056, 0.0000, 0.0157, 0.0526, 0.0000, 0.0000],\n",
       "         [0.0463, 0.0000, 0.0734, 0.0571, 0.0000, 0.0000],\n",
       "         [0.0658, 0.0000, 0.0734, 0.0747, 0.0000, 0.0000],\n",
       "         [0.0658, 0.0000, 0.0848, 0.0934, 0.0000, 0.0000],\n",
       "         [0.0652, 0.0000, 0.0152, 0.0661, 0.0000, 0.0000],\n",
       "         [0.0114, 0.0000, 0.0812, 0.0870, 0.0000, 0.0000],\n",
       "         [0.0432, 0.0000, 0.0795, 0.0202, 0.0000, 0.0000],\n",
       "         [0.0857, 0.0000, 0.0080, 0.0747, 0.0000, 0.0000],\n",
       "         [0.0432, 0.0000, 0.0812, 0.0034, 0.0000, 0.0000],\n",
       "         [0.0114, 0.0000, 0.0844, 0.0266, 0.0000, 0.0000],\n",
       "         [0.1056, 0.0000, 0.0872, 0.0450, 0.0000, 0.0000],\n",
       "         [0.0658, 0.0000, 0.0844, 0.0760, 0.0000, 0.0000],\n",
       "         [0.0759, 0.0000, 0.0812, 0.0450, 0.0000, 0.0000],\n",
       "         [0.1056, 0.0000, 0.0157, 0.0934, 0.0000, 0.0000],\n",
       "         [0.0563, 0.0000, 0.0812, 0.0266, 0.0000, 0.0000],\n",
       "         [0.0759, 0.0000, 0.0795, 0.0760, 0.0000, 0.0000],\n",
       "         [0.0759, 0.0000, 0.0795, 0.0526, 0.0000, 0.0000],\n",
       "         [0.0760, 0.0000, 0.0812, 0.0870, 0.0000, 0.0000],\n",
       "         [0.1056, 0.0000, 0.0734, 0.0934, 0.0000, 0.0000],\n",
       "         [0.0156, 0.0000, 0.0384, 0.0571, 0.0000, 0.0000],\n",
       "         [0.0563, 0.0000, 0.0583, 0.0581, 0.0000, 0.0000],\n",
       "         [0.1056, 0.0000, 0.0872, 0.0250, 0.0000, 0.0000],\n",
       "         [0.0658, 0.0000, 0.0844, 0.0889, 0.0000, 0.0000],\n",
       "         [0.1056, 0.0000, 0.0775, 0.0221, 0.0000, 0.0000],\n",
       "         [0.0407, 0.0000, 0.0872, 0.0760, 0.0000, 0.0000],\n",
       "         [0.0857, 0.0000, 0.0812, 0.0934, 0.0000, 0.0000],\n",
       "         [0.0407, 0.0000, 0.0331, 0.0870, 0.0000, 0.0000],\n",
       "         [0.1056, 0.0000, 0.0848, 0.0450, 0.0000, 0.0000],\n",
       "         [0.1056, 0.0000, 0.0210, 0.0889, 0.0000, 0.0000],\n",
       "         [0.0235, 0.0000, 0.0945, 0.0368, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4179,  1.0070, -0.4219, -3.9579, -2.7612, -0.4937, -4.3845,  0.2234,\n",
       "         -0.3561, -0.3228, -1.6439, -0.3902,  0.1866,  0.0304,  1.9634, -0.2119,\n",
       "          0.3968, -4.5075, -0.9949,  5.5444],\n",
       "        [-1.4001,  2.0268, -1.0783,  0.0530, -0.6134, -0.2297,  0.0709,  1.3258,\n",
       "          0.3986,  1.1676, -1.9901,  0.2156, -0.5675, -0.5437, -0.2863, -1.9482,\n",
       "         -2.4567, -1.1607, -1.2261,  0.8671],\n",
       "        [-0.2373, -0.8207, -0.6469,  1.3175, -0.9699, -0.4068,  0.8829,  1.2168,\n",
       "         -1.1801, -0.9565, -1.4848, -1.1996, -0.6022,  1.9340, -0.3521, -1.2212,\n",
       "         -2.0115, -2.1553, -1.1180,  0.2196]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lik, ham_s = loglik_potts(param_embeddings2, fields2, logZ, samples_full) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.2376,  -3.7111,  -4.4863,  -2.7635,   0.8379,  -0.0753,  -0.6168,\n",
       "           3.4276,   9.2806,  -2.9406,   1.2479,  -1.1388,  -4.7617,  -2.3241,\n",
       "           0.3153,  -0.3997,   7.0578, -11.8621,   4.1278,   0.3478,  -3.8795,\n",
       "           0.6578,  -0.1433,   2.4244,  -0.4940,  -3.0831,  -7.9304,  -2.1165,\n",
       "          -5.8685,  -1.9086,   0.1472,   0.8621,   1.9392,   2.3627,  -5.6857,\n",
       "          -8.7938,   0.1421,   9.6357,  -2.3659,   3.7855],\n",
       "        [ -5.2727,  -2.4764,   0.6880,  -1.0528,  11.7529,  -1.4121,  -2.1735,\n",
       "           6.6860,   0.1185,   0.8783,  -3.3314,   4.2387,  -0.7928,  -0.7989,\n",
       "          -3.4933,  -2.2688,  -2.4604,  -7.2371,   3.3306,  -0.3710,  -0.1299,\n",
       "           2.5268,  -0.9580,   0.7442,   0.4685,  -0.0887, -10.8362, -11.0541,\n",
       "          -6.4370, -11.0569,  -4.1219,  -1.6273,  -2.3082,  -6.5055,   0.9592,\n",
       "           7.9138,  -4.4997,  -7.5472,   5.1019,  -1.5960],\n",
       "        [ -1.7896,  -2.7972,   2.0103,  -0.4200,  -6.4310,  -0.2355,  -0.1247,\n",
       "           1.4732,  -4.8403,  -1.5443,  -4.4838,  -2.7146,   0.2579,  -0.0854,\n",
       "           4.8778,   3.8781,  -1.6268,  -2.7392,  -2.0812,  -0.3585,  -1.7828,\n",
       "           0.3935,   0.7475,  -1.5036,  -3.9853,  -0.8104,   2.1354,  -1.6606,\n",
       "           3.2701,   1.9601,  -3.8283,  -0.6517,   8.0582,  -0.4293,   1.2989,\n",
       "          -3.8585,  -0.0769,   1.7256,   0.5754,   0.9935]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6494, -0.9912, -0.1080])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = loglik_potts(V, fields, logZ, samples_full) - loglik_indep(fi, samples_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_noise = torch.zeros((B,2*M))\n",
    "mask_noise[:, 0:M] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 8.3446e-07, 1.8893e+01, 1.8696e+01],\n",
       "        [0.0000e+00, 0.0000e+00, 1.7686e+01, 1.7921e+01],\n",
       "        [0.0000e+00, 0.0000e+00, 2.1240e+01, 2.3362e+01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nce(V, fields, Z, msas_embedded, samples_ind_embedded, mask_noise, fi, N, M, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
